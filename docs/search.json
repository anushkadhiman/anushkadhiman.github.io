[
  {
    "objectID": "insights.html",
    "href": "insights.html",
    "title": "Insights",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDecision Tree implementation from scratch with Python\n\n\n\n\n\n\n\n\nJan 20, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nK Mean implementation from scratch with Python\n\n\n\n\n\n\n\n\nJan 18, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nK-Nearest implementation from scratch with Python\n\n\n\n\n\n\n\n\nJan 17, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nSupport Vector Machine implementation from scratch with Python\n\n\n\n\n\n\n\n\nJan 15, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression implementation from scratch with Python\n\n\n\n\n\n\n\n\nJan 14, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression implementation from scratch with Python\n\n\n\n\n\n\n\n\nJan 13, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nConditional Probability and Bayes Theorem\n\n\n\n\n\n\n\n\nJan 11, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nProbability\n\n\n\n\n\n\n\n\nJan 9, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nPermutation and Combination\n\n\n\n\n\n\n\n\nJan 7, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html",
    "title": "Permutation and Combination",
    "section": "",
    "text": "The study of permutations and combinations is concerned with determining the number of different ways of arranging and selecting objects out of a given number of objects, without actually listing them. There are some basic counting techniques which will be useful in determining the number of different ways of arranging or selecting objects. The two basic counting principles are given below:"
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html#overview",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html#overview",
    "title": "Permutation and Combination",
    "section": "",
    "text": "The study of permutations and combinations is concerned with determining the number of different ways of arranging and selecting objects out of a given number of objects, without actually listing them. There are some basic counting techniques which will be useful in determining the number of different ways of arranging or selecting objects. The two basic counting principles are given below:"
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html#fundamental-principle-of-counting",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html#fundamental-principle-of-counting",
    "title": "Permutation and Combination",
    "section": "Fundamental principle of counting",
    "text": "Fundamental principle of counting\n\nMultiplication principle\nSuppose an event E can occur in m different ways and associated with each way of occurring of E, another event F can occur in n different ways, then the total number of occurrence of the two events in the given order is m √ó n .\nFor example, if you roll a six-sided dice and a two sided coin, then there are 6 √ó 2 = 12 possible outcomes.\nTherefore, this principle can be use in everyday life when you need to calculate the number of possibilities that exist when combining choices.\n\n# The total number of possible combinations (dice, coin) can be calculated using the fundamental principle of counting.\n\n# Number of choices for dice and coin\ndice_choices = 6 # 1, 2, 3, 4, 5, 6\ncoin_choices = 2  # H, T\n\n# Total combinations using the Multiplication Principle of Counting\ntotal_combinations = dice_choices * coin_choices\n\nprint(f\"Total number of possible combinations: {total_combinations}\")\n\nTotal number of possible combinations: 12\n\n\n\n\nAddition principle\nIf an event E can occur in m ways and another event F can occur in n ways, and suppose that both can not occur together, then E or F can occur in m + n ways.\n\n# The total number of possible combinations (dice, coin) can be calculated using addition principle of counting.\n\n# Number of choices for dice and coin\ndice_choices = 6 # 1, 2, 3, 4, 5, 6\ncoin_choices = 2  # H, T\n\n# Total combinations using the Addition Principle of Counting\ntotal_combinations = dice_choices + coin_choices\n\nprint(f\"Total number of possible combinations: {total_combinations}\")\n\nTotal number of possible combinations: 8"
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html#permutations",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html#permutations",
    "title": "Permutation and Combination",
    "section": "Permutations",
    "text": "Permutations\nA permutation is an arrangement of objects in a definite order.\n\nPermutation of n different objects:\nThe number of permutations of n objects taken all at a time, denoted by the symbol \\(^nP_n\\) , is given by\nwhere \\({n!}\\) = n(n ‚Äì 1) (n ‚Äì 2) ‚Ä¶ 3.2.1, read as factorial n, or n factorial.\nThere are basically two types of permutation:\n\n\nWhen repetition of objects is allowed\nIn this case, you can finds all possible arrangements of a set of objects. And here, the order of the objects is important.\nThe number of permutations of n things taken all at a time, when repetion of objects is allowed is \\(n^n\\).\nThe number of permutations of n objects, taken r at a time, when repetition of objects is allowed, is \\(n^r\\).\n\n\nWhen repetition of objects is not allowed\nIn this case, you cannot select the same item multiple times while arranging a set of items. Essentially, each item can only be used once in the arrangement, meaning the number of available choices decreases with each selection made.\nThe number of permutations of n objects taken r at a time, where 0 &lt; r ‚â§ n, denoted by \\(^nP_r\\) , is given by\n\\[ ^nP_r = \\frac{n!}{(n-r)!} \\]\nwhere:\n- \\(n\\) is the number of elements in the set.\n- \\(r\\) is the number of elements taken together.\n\n\nPermutations when the objects are not distinct: they are identical\nIn this case, when objects are identical, many arrangements will appear the same, so you need to divide by the number of ways to arrange the identical objects among themselves.\nThe number of permutations of n objects of which r1 are of one kind, r2 are of second kind, ‚Ä¶, rk are of kth kind and the rest if any, are of different kinds is\n\\[ \\frac{n!}{(r1!*r2!*r3!..rk)!} \\]"
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html#combinations",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html#combinations",
    "title": "Permutation and Combination",
    "section": "Combinations",
    "text": "Combinations\nThis method is used to calculate the total number of outcomes when order doesn‚Äôt matter. Essentially, we are not interested in arranging rather in selecting r objects from given n objects.\nThere are also two types of combinations:\n\nCombinations without Repetition\nIn this case, you can only select each item once when choosing a group from a set. For instance, picking lottery numbers, where each number drawn cannot be repeated.\nThe formula for calculating the number of combinations from \\(n\\) elements taken \\(r\\) at a time is given by:\n\\[^n C_r = \\frac{n!}{(n-r)! r!}\\]\n\n\nCombinations with Repetition\nIn this case, when selecting items from a set, you can choose the same item multiple times. For instance, selecting flavors for ice cream cones, where you could choose two scoops of chocolate.\nIf we choose a set of r items from n types of items, where repetition is allowed and the number items we are choosing from is essentially unlimited, the number of selections possible is given by:\n\\[^n C_r = \\frac{(r+n-1)!}{(n-1)! r!}\\]\nLet‚Äôs explore some examples to better understand these concepts."
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html#permutation-and-combination-in-python",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html#permutation-and-combination-in-python",
    "title": "Permutation and Combination",
    "section": "Permutation and Combination in Python",
    "text": "Permutation and Combination in Python\nThese methods can be found in itertools package.\n\nPermutation\nWe can use itertools module to generate permutations of objects efficiently. Here‚Äôs how to use itertools for the three types of permutations that we‚Äôve discussed lately:\n1. Permutations of ùëõ Different Objects (No Repetition)\nFor a set of ùëõ distinct objects, itertools.permutations() can generate all possible permutations of those objects. This is for the case where you want to arrange all n different objects without repetition.\n\nimport itertools\n\n# List of distinct objects\nobjects = ['A', 'B', 'C']\n\n# Generate all permutations of the objects\npermutations = list(itertools.permutations(objects))\n\n# Output the permutations and the total number of permutations\nprint(\"Permutations of distinct objects:\", permutations)\nprint(\"Total number of permutations:\", len(permutations))\n\nPermutations of distinct objects: [('A', 'B', 'C'), ('A', 'C', 'B'), ('B', 'A', 'C'), ('B', 'C', 'A'), ('C', 'A', 'B'), ('C', 'B', 'A')]\nTotal number of permutations: 6\n\n\n2. Permutations When Repetition of Objects is Allowed\nIn this case, itertools.product() can be used to simulate the scenario where repetition is allowed. The result will generate all possible combinations where the same object can appear multiple times.\n\n# Generate all permutations of length 2, allowing repetition\npermutations_with_repetition = list(itertools.product(objects, repeat=2))\n\n# Output the permutations and the total number of permutations\nprint(\"Permutations with repetition allowed:\", permutations_with_repetition)\nprint(\"Total number of permutations:\", len(permutations_with_repetition))\n\nPermutations with repetition allowed: [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')]\nTotal number of permutations: 9\n\n\nIf you want to generate permutations for selecting and arranging a specific number of elements from a set.\nPermutaion taking 2 elements together from a set of 3 elements:\n\\[ ^3P_2 = \\frac{3!}{(3-2)!} = \\frac{3!}{1!} = \\frac{6}{1} = 6 \\]\nPermutation taking 3 elements together from a set of 3 elements:\n\\[ ^3P_3 = \\frac{3!}{(3-3)!} = \\frac{3!}{0!} = \\frac{6}{0} = 6 \\]\n\nchar_set = ['A', 'B', 'C'] # define a charater set of 3 elements\n\npermutations1 = list(itertools.permutations(char_set, 2)) # permutations taking two elements\npermutations2 = list(itertools.permutations(char_set, 3)) # permutations taking three elements\n\n# Output the permutations taking two elements and taking three elements\nprint(\"Permutations of 2 elements from 3 elements:\", permutations1)\nprint(\"Permutations of 3 elements from 3 elements:\", permutations2)\n\nPermutations of 2 elements from 3 elements: [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')]\nPermutations of 3 elements from 3 elements: [('A', 'B', 'C'), ('A', 'C', 'B'), ('B', 'A', 'C'), ('B', 'C', 'A'), ('C', 'A', 'B'), ('C', 'B', 'A')]\n\n\n3. Permutations When the Objects are Not Distinct\nFor permutations with non-distinct objects, itertools.permutations will still generate all permutations, but you need to account for repeated objects manually by removing duplicates after generating the permutations.\n\nimport itertools\n\n# List of objects, some of which are repeated\nobjects = ['A', 'A', 'B']\n\n# Generate all permutations and remove duplicates by converting to a set\ndistinct_permutations = set(itertools.permutations(objects))\n\n# Output the distinct permutations and the total number of distinct permutations\nprint(\"Distinct permutations of non-distinct objects:\", distinct_permutations)\nprint(\"Total number of distinct permutations:\", len(distinct_permutations))\n\nDistinct permutations of non-distinct objects: {('B', 'A', 'A'), ('A', 'B', 'A'), ('A', 'A', 'B')}\nTotal number of distinct permutations: 3\n\n\nNow, let‚Äôs take a look at combinations\nCombinations without Repetition\nCombination taking 2 elements together from a set of 3 elements:\n\\[ ^3C_2 = \\frac{3!}{(3-2)!2!} = \\frac{3!}{1!*2!} = \\frac{6}{2} = 3 \\]\nCombination taking 3 elements together from a set of 3 elements:\n\\[ ^3C_3 = \\frac{3!}{(3-3)!3!} = \\frac{3!}{0!*3!} = \\frac{6}{6} = 1 \\]\n\n# import combinations using itertools package\nfrom itertools import combinations \n\ncombination1 = list(combinations(char_set, 2)) # combination taking two elements\n\n# Output the combination taking two elements and the total number of combinations\nprint(\"Combinations of 2 elements from 3 elements:\", combination1)\nprint(\"Total number of combinations of 2 elements from 3 elements:\", len(combination1))\n\nCombinations of 2 elements from 3 elements: [('A', 'B'), ('A', 'C'), ('B', 'C')]\nTotal number of combinations of 2 elements from 3 elements: 3\n\n\n\ncombination2 = list(combinations(char_set, 3)) # combination taking three elements\n\n# Output the combination taking three elements and the total number of combinations\nprint(\"Combinations of 2 elements from 3 elements:\", combination2)\nprint(\"Total number of combinations of 3 elements from 3 elements:\", len(combination2))\n\nCombinations of 2 elements from 3 elements: [('A', 'B', 'C')]\nTotal number of combinations of 3 elements from 3 elements: 1\n\n\nCombinations with Repetiton\nThis function generates all possible combinations of \\(r\\) elements from a given iterable, allowing elements to be selected multiple times. It‚Äôs useful when repetitions are allowed in the selection process.\nCombination taking 2 elements together from a set of 3 elements:\n\\[ ^3C_2 = \\frac{(2+3-1)!}{(3-1)!*2!} = \\frac{4!}{2!*2!} = \\frac{24}{2*2} = 6 \\]\nCombination taking 3 elements together from a set of 3 elements:\n\\[ ^3C_3 = \\frac{(3+3-1)!}{(3-1)!*3!} = \\frac{5!}{2!*3!} = \\frac{120}{2*6} = 10 \\]\n\nfrom itertools import combinations_with_replacement \n\ncombination_with_replacement1 = list(combinations_with_replacement(char_set, 2)) #combination taking two elements with replacement\n\n# Output the combination taking three elements and the total number of combinations\nprint(\"Combinations of 2 elements from 3 elements:\", combination_with_replacement1)\nprint(\"Total number of combinations of 2 elements from 3 elements:\", len(combination_with_replacement1))\n\nCombinations of 2 elements from 3 elements: [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')]\nTotal number of combinations of 3 elements from 3 elements: 6\n\n\n\ncombination_with_replacement2 = list(combinations_with_replacement(char_set, 3)) #combination taking three elements with replacement\n\n# Output the combination taking three elements and the total number of combinations\nprint(\"Combinations of 3 elements from 3 elements:\", combination_with_replacement2)\nprint(\"Total number of combinations of 3 elements from 3 elements:\", len(combination_with_replacement2))\n\nCombinations of 3 elements from 3 elements: [('A', 'A', 'A'), ('A', 'A', 'B'), ('A', 'A', 'C'), ('A', 'B', 'B'), ('A', 'B', 'C'), ('A', 'C', 'C'), ('B', 'B', 'B'), ('B', 'B', 'C'), ('B', 'C', 'C'), ('C', 'C', 'C')]\nTotal number of combinations of 3 elements from 3 elements: 10"
  },
  {
    "objectID": "insights/StatisticsandProbability/PermutationandCombination.html#conclusion",
    "href": "insights/StatisticsandProbability/PermutationandCombination.html#conclusion",
    "title": "Permutation and Combination",
    "section": "Conclusion",
    "text": "Conclusion\nThis article explores combinatorics, specifically permutations and combinations, implementing it using python. It provides mathematical theory and python implementation in solving broader problems.\nPermutations and Combinations have been crucial in fields ranging from cryptography to the optimization of AI algorithms.\nFor instance, in machine learning is feature selection in model training.\n\nPermutations: It can be used to generate different sets of features to test their performance, optimizing the model‚Äôs accuracy.\nCombinations: It can be used to determine the number of ways features can be selected from a larger set, helping in reducing model complexity and improving interpretability.\n\nI‚Äôd love any feedback you may have. Feel free to reach out and follow SOTA Insights for more such articles!"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/logistic_regression.html#logistic-regression",
    "href": "insights/StatisticsandProbability/MachineLearning/logistic_regression.html#logistic-regression",
    "title": "Logistic Regression implementation from scratch with Python",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nLogistic regression is a statistical method used for binary classification, which means it is used to predict the probability of an event occurring or not. It is a type of generalized linear model that is used when the dependent variable is binary or categorical.\nIn logistic regression, the dependent variable is binary (i.e., it can take on one of two values, usually 0 or 1), and the independent variables can be either continuous or categorical. The goal of logistic regression is to find the relationship between the independent variables and the dependent variable by estimating the probability of the dependent variable being 1 given the values of the independent variables.\nThe logistic regression model uses a logistic function (also known as the sigmoid function) to map the input values of the independent variables to a value between 0 and 1, which represents the probability of the dependent variable being 1.\nThe logistic function is defined as:\n\\[ p = \\frac{1}{1 + e^{-z}} \\]\nwhere: - ( p ) is the predicted probability of the dependent variable being 1. - ( e ) is the base of the natural logarithm. - ( z ) is the linear combination of the independent variables.\nThe logistic regression model estimates the values of the coefficients of the independent variables that maximize the likelihood of observing the data given the model. This is typically done using maximum likelihood estimation or gradient descent optimization.\nAfter training model, model takes input value of the independent variables and obtaining the predicted probability of the dependent variable being 1. The model can then classify the new observation as 1 or 0 based on a user defined threshold probability value."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/logistic_regression.html#logistic-regression-code-implementation-using-python",
    "href": "insights/StatisticsandProbability/MachineLearning/logistic_regression.html#logistic-regression-code-implementation-using-python",
    "title": "Logistic Regression implementation from scratch with Python",
    "section": "Logistic regression Code Implementation using python",
    "text": "Logistic regression Code Implementation using python\nHere‚Äôs an example implementation using gradient descent optimization:\n\nimport numpy as np\n\nclass LogisticRegression:\n    \n    def __init__(self, learning_rate=0.01, n_iters=1000):\n        self.learning_rate = learning_rate # The learning rate controls how large the update step will be.\n        self.n_iters = n_iters\n        self.weights = None\n        self.bias = None\n        \n    def fit(self, X, y):\n        # initialize weights and bias to zeros\n        n_samples, n_features = X.shape\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        \n        # gradient descent optimization\n        for i in range(self.n_iters):\n            # calculate predicted probabilities and cost\n            z = np.dot(X, self.weights) + self.bias\n            y_pred = self._sigmoid(z)\n\n            # the logistic loss or binary cross-entropy. It computes how well the predicted probabilities (y_pred) match the actual target values (y).\n            cost = (-1 / n_samples) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)) \n            \n            # calculate gradients of the cost function wrt weights.\n            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y)) # the average of the product of the error (y_pred - y) and each feature (X.T).\n            db = (1 / n_samples) * np.sum(y_pred - y) # the average of the errors.\n             \n            # update weights and bias\n            self.weights -= self.learning_rate * dw\n            self.bias -= self.learning_rate * db\n            \n    def predict(self, X):\n        # calculate predicted probabilities\n        z = np.dot(X, self.weights) + self.bias\n        y_pred = self._sigmoid(z)\n        # convert probabilities to binary predictions\n        return np.round(y_pred).astype(int)\n    \n    def _sigmoid(self, z):\n\n        \"\"\"Implements the sigmoid function, which maps any real-valued number to a value between 0 and 1.\"\"\"\n\n        return 1 / (1 + np.exp(-z))\n\nLet‚Äôs test our code\nAssume we have some training data (X) and corresponding labels (y), and we want to fit a logistic regression model to it.\n\n# create sample dataset\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\ny = np.array([0, 0, 1, 1, 1])\n\n# initialize logistic regression model\nlr = LogisticRegression()\n\n# train model on sample dataset\nlr.fit(X, y)\n\n# make predictions on new data\nX_new = np.array([[6, 7], [7, 8]])\ny_pred = lr.predict(X_new)\n\nprint(y_pred)  # [1, 1]\n\n[1 1]\n\n\nThe model predicts [1, 1], which corresponds to:\nSample 1: The predicted probability is greater than 0.5, so the model predicts 1, which matches the actual label.\nSample 2: The predicted probability is greater than 0.5, so the model predicts 1, which matches the actual label.\nHere in the code, we will add regularization and use a more sophisticated optimization algorithm to improve the code\n\nMini-Batch Gradient Descent is used: In each iteration, a random batch of data is selected, and the model computes the predictions and updates the weights and bias using mini-batch gradient descent.\nApply Regularization (if specified): Regularization is added to prevent overfitting by penalizing large weights.\n\nL1 Regularization: The L1 regularization term penalizes the sum of the absolute values of the weights. L2 Regularization: The L2 regularization term penalizes the sum of the squares of the weights\n\nimport numpy as np\n\nclass LogisticRegression:\n    \n    def __init__(self, learning_rate=0.01, n_iters=1000, regularization='l2', reg_strength=0.1, batch_size=32):\n        self.learning_rate = learning_rate\n        self.n_iters = n_iters\n        self.regularization = regularization\n        self.reg_strength = reg_strength\n        self.batch_size = batch_size\n        self.weights = None\n        self.bias = None\n        \n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        n_batches = n_samples // self.batch_size\n        for i in range(self.n_iters):\n            batch_indices = np.random.choice(n_samples, self.batch_size)\n            X_batch = X[batch_indices]\n            y_batch = y[batch_indices]\n            z = np.dot(X_batch, self.weights) + self.bias\n            y_pred = self._sigmoid(z)\n            cost = (-1 / self.batch_size) * np.sum(y_batch * np.log(y_pred) + (1 - y_batch) * np.log(1 - y_pred))\n            if self.regularization == 'l2':\n                reg_cost = (self.reg_strength / (2 * n_samples)) * np.sum(self.weights ** 2)\n                cost += reg_cost\n            elif self.regularization == 'l1':\n                reg_cost = (self.reg_strength / (2 * n_samples)) * np.sum(np.abs(self.weights))\n                cost += reg_cost\n            dw = (1 / self.batch_size) * np.dot(X_batch.T, (y_pred - y_batch))\n            db = (1 / self.batch_size) * np.sum(y_pred - y_batch)\n            if self.regularization == 'l2':\n                dw += (self.reg_strength / n_samples) * self.weights\n            elif self.regularization == 'l1':\n                dw += (self.reg_strength / n_samples) * np.sign(self.weights)\n            self.weights -= self.learning_rate * dw\n            self.bias -= self.learning_rate * db\n            \n    def predict(self, X):\n        z = np.dot(X, self.weights) + self.bias\n        y_pred = self._sigmoid(z)\n        return np.round(y_pred).astype(int)\n    \n    def _sigmoid(self, z):\n        return 1 / (1 + np.exp(-z))\n\nLet‚Äôs test our code\n\n# create sample dataset\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\ny = np.array([0, 0, 1, 1, 1])\n\n# initialize logistic regression model\nlr = LogisticRegression(learning_rate=0.01, n_iters=1000, regularization='l2', reg_strength=0.1, batch_size=2)\n\n# train model on sample dataset\nlr.fit(X, y)\n\n# make predictions on new data\nX_new = np.array([[6, 7], [7, 8]])\ny_pred = lr.predict(X_new)\n\nprint(y_pred)  # [1, 1]\n\n[1 1]"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/logistic_regression.html#visualization",
    "href": "insights/StatisticsandProbability/MachineLearning/logistic_regression.html#visualization",
    "title": "Logistic Regression implementation from scratch with Python",
    "section": "Visualization",
    "text": "Visualization\nHere‚Äôs an example of how to visualize the decision boundary of the LogisticRegression class on a 2D dataset using the matplotlib library:\n\nimport matplotlib.pyplot as plt\n\n# create 2D dataset\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\ny = np.array([0, 0, 1, 1, 1])\n\n# Plot the input data\nplt.figure(figsize=(8, 6))\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', marker='o', edgecolor='k', s=100, alpha=0.7)\n\n# Create a grid to plot the decision boundary\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\nZ = lr.predict(np.c_[xx.ravel(), yy.ravel()])  # Predict over the grid\nZ = Z.reshape(xx.shape)  # Reshape to fit the grid\n\n# Plot the decision boundary\nplt.contourf(xx, yy, Z, alpha=0.4, cmap='coolwarm')\nplt.colorbar()\n\n# Set plot labels and title\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.title('Logistic Regression: Data and Decision Boundary')\n\n# Show plot\nplt.show()"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/knn.html#knn-code-implementation-using-python",
    "href": "insights/StatisticsandProbability/MachineLearning/knn.html#knn-code-implementation-using-python",
    "title": "K-Nearest implementation from scratch with Python",
    "section": "KNN Code Implementation using python",
    "text": "KNN Code Implementation using python\nHere‚Äôs an example implementation of a KNN classifier in python\n\nfrom collections import Counter\nimport numpy as np\n\nclass KNN:\n    def __init__(self, k=3, distance='euclidean'):\n        self.k = k\n        self.distance = distance\n        \n    def fit(self, X_train, y_train):\n        self.X_train = X_train\n        self.y_train = y_train\n        \n    def predict(self, X_test):\n        y_pred = []\n        for x in X_test:\n            # Compute distances between the test point and all training points\n            if self.distance == 'euclidean':\n                distances = np.linalg.norm(self.X_train - x, axis=1)\n            elif self.distance == 'manhattan':\n                distances = np.sum(np.abs(self.X_train - x), axis=1)\n            else:\n                distances = np.power(np.sum(np.power(np.abs(self.X_train - x), self.distance), axis=1), 1/self.distance)\n                \n            # Select the k nearest neighbors\n            nearest_indices = np.argsort(distances)[:self.k]\n            nearest_labels = self.y_train[nearest_indices]\n            \n            # Assign the class label that appears most frequently among the k nearest neighbors\n            label = Counter(nearest_labels).most_common(1)[0][0]\n            y_pred.append(label)\n        \n        return np.array(y_pred)\n\nUnlike many machine learning algorithms, k-NN doesn‚Äôt need explicit training or model fitting‚Äîit‚Äôs a lazy learner that simply stores the training data and uses it during prediction.\n\nMaking Predictions:\nThis method predicts the class labels for the test data based on the k-NN algorithm. Here‚Äôs how the prediction works:\nLoop over each test point:\nFor each test point (x), the method computes the distances to all points in the training set (X_train). Distance Calculation:\n\nIf the distance parameter is ‚Äòeuclidean‚Äô, it uses the Euclidean distance to compute the distance between the test point and each training point. This is done using np.linalg.norm(self.X_train - x, axis=1), which calculates the L2 norm (Euclidean distance).\nIf the distance parameter is ‚Äòmanhattan‚Äô, it uses the Manhattan distance (L1 norm) to compute the distance using np.sum(np.abs(self.X_train - x), axis=1).\nIf a custom distance (like Minkowski) is provided, it calculates that distance using np.power(‚Ä¶).\n\nFind the k Nearest Neighbors:\nAfter calculating the distances, the np.argsort(distances) function is used to sort the distances in ascending order, and the first k indices (nearest neighbors) are selected using [:self.k].\nMajority Voting:\nThe labels of the k nearest neighbors are retrieved from self.y_train[nearest_indices]. A majority vote is performed using the Counter class from the collections module, which counts the frequency of each class label among the k neighbors. The most common label is then assigned as the predicted label for the test point.\nFinal Prediction:\nThe predicted label is appended to the y_pred list, which stores the predicted labels for all the test points.\nDistance Calculation:\n\nIf the distance parameter is ‚Äòeuclidean‚Äô, it uses the Euclidean distance to compute the distance between the test point and each training point. This is done using np.linalg.norm(self.X_train - x, axis=1), which calculates the L2 norm (Euclidean distance).\nIf the distance parameter is ‚Äòmanhattan‚Äô, it uses the Manhattan distance (L1 norm) to compute the distance using np.sum(np.abs(self.X_train - x), axis=1).\nIf a custom distance (like Minkowski) is provided, it calculates that distance using np.power(‚Ä¶).\n\nAfter iterating over all test points, the method returns the predicted labels as a numpy array\n\n\nKey Concepts:\n\nLazy Learning: KNN doesn‚Äôt perform any training in the traditional sense (i.e., there is no model that is learned). Instead, it memorizes the training data and makes predictions during the testing phase by comparing new test data points with the stored training data.\nDistance Metric: The choice of distance metric is crucial. The default is Euclidean distance, which works well for most cases, but other distance metrics like Manhattan or Minkowski can be used depending on the problem.\nk (Number of Neighbors): The value of k determines how many nearest neighbors the algorithm will consider when making predictions. A small k may be noisy and sensitive to outliers, while a large k may smooth out the predictions but might lose the ability to capture the fine details of the data.\n\nLet‚Äôs test our code,\n\nfrom collections import Counter\nimport numpy as np\n\n# Creating a simple dataset\nX_train = np.array([[1, 2], [2, 3], [3, 3], [6, 5], [7, 8], [8, 8]])\ny_train = np.array([0, 0, 0, 1, 1, 1])\n\n# Creating a KNN classifier object\nknn = KNN(k=3, distance='euclidean')\n\n# Fit the model with training data\nknn.fit(X_train, y_train)\n\n# Create a test sample\nX_test = np.array([[3, 3], [7, 7]])\n\n# Predict the class labels for the test sample\ny_pred = knn.predict(X_test)\n\nprint(\"Predicted labels:\", y_pred)\n\nPredicted labels: [0 1]\n\n\nTest Point 1 ([3, 3]): The nearest 3 neighbors are all from class 0, so it predicts 0.\nTest Point 2 ([7, 7]): The nearest 3 neighbors are from class 1, so it predicts 1.\nNow, we‚Äôll visualize the dataset and the KNN classification results.\nLet‚Äôs go through this step by step:\n\nLoad the Iris dataset\nSplit the data into training and test sets\nTrain the KNN classifier\nMake predictions on the test data\nEvaluate accuracy\nVisualize the data and decision boundary (for a 2D projection)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA  # To reduce dimensionality for visualization\n\n# Load the iris dataset\niris = load_iris()\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n\n# Create a KNN classifier with k=5 and euclidean distance\nknn = KNN(k=5, distance='euclidean')\n\n# Train the classifier on the training data\nknn.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = knn.predict(X_test)\n\n# Compute the accuracy of the classifier\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\n# Visualization\n# First, reduce the dimensionality to 2D using PCA for visualization\npca = PCA(n_components=2)\nX_train_2d = pca.fit_transform(X_train)\nX_test_2d = pca.transform(X_test)\n\n\nAccuracy: 1.0\n\n\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the iris dataset\niris = load_iris()\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n\n# Create a KNN classifier with k=5 and euclidean distance\nknn = KNN(k=5, distance='euclidean')\n\n# Train the classifier on the training data\nknn.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = knn.predict(X_test)\n\n# Compute the accuracy of the classifier\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\nAccuracy: 1.0\n\n\nThis may vary slightly based on how the model generalizes to the test data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learn, explore, and connect.",
    "section": "",
    "text": "At SOTA Insights, you‚Äôll find:\n\nInsights: Articles and tutorials on SOTA algorithms and architectures, complete with code and visualizations.\nBlogs: Exploring AI trends, tech, books, and mindful productivity.\n\nSOTA Insights is just the beginning of my journey to explore, learn, and contribute to the AI ecosystem. I hope you‚Äôll join me in this mission."
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html",
    "href": "blog/whats_next_in_ai/index.html",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "",
    "text": "While 2024 has been a year of incredible developments in artificial intelligence, and more is to come. From generative AI and large language models (LLMs) to multimodal AI, agentic AI, and quantum AI, we are excited to watch how AI will develop in coming years. Workflows across sectors will be further accelerated by these technologies, bringing about revolutionary change and opening up new opportunities.\nAs AI develops further, scientists are concentrating on improving fundamental ideas, creating new applications, and resolving the shortcomings of existing models.\nThe following key fields of AI research are anticipated to have substantial advancements:"
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html#multimodal-ai",
    "href": "blog/whats_next_in_ai/index.html#multimodal-ai",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "Multimodal AI",
    "text": "Multimodal AI\nMultimodal AI is a type of artificial intelligence that can understand and generate multiple data inputs simultaneously, including text, images, and sound. It is trained on large datasets to learn relationships between different modalities and fuse them effectively. It can perform tasks like image captioning, text-to-image generation, video understanding, human-computer interaction, and robot interaction, offering significant potential for real-world applications.\nHere are some examples,\nChatGPT offers multimodal capabilities, allowing users to interact with the chatbot in various ways. Users can upload images as prompts, which the chatbot uses to generate responses. Voice input is also available for hands-free tasks, and responses can be generated in one of five natural-sounding voices. Additionally, ChatGPT Plus and Enterprise users can generate images from text descriptions directly within the ChatGPT interface with the DALL-E GPT.\nGoogle Gemini is gaining popularity in the AI space, in certain areas due to its fresh data. Gemini integrates with various data sources like Google Flights, Maps, Hotels, Workspace, and YouTube. Its dynamic communication with tools like Maps and Hotels allows for real-time updates on queries related to those topics.\n\nUse Cases:\nPersonalized Nutrition: The USDA‚Äôs MyPlate allows individuals to plan their meals based on various factors such as age, sex, weight, height, and physical activity level. Future plans could include additional data like blood test results, health questionnaires, genotype, or microbiome. Important features need to be identified using large clinical studies with advanced feature selection methods. The USDA Nutritional Penotyping study includes over 5000 variables from self-reporting diet questionnaires and blood tests, and millions from high-throughput ‚Äúomics‚Äù analyses. ML analyses of this data can serve two purposes: developing a mechanistic understanding of the relationship between diet and health and developing personalized nutrition models to predict health effects.\nMedical Images: M-LLMs are advanced medical imaging tools that can improve diagnostic accuracy and efficiency in various image modalities like x-rays, MRI scans, CT scans, positron emission tomography scans, ultrasound images, digital pathology slides, and retinal images. These tools provide unique insights into the body‚Äôs internal structures, aiding in early disease detection, diagnosis, and monitoring. For example, in radiology, M-LLMs analyze CT and MRI images to identify anomalies and generate automated reports. They also allow annotation and tagging of medical images with keywords, enabling additional analytics applications. In pathology, they interpret tissue sample slides to identify disease markers. In dermatology, they assess skin lesions for early detection of skin cancers.\nAI Personalised Nutritions"
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html#agentic-ai",
    "href": "blog/whats_next_in_ai/index.html#agentic-ai",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "Agentic AI",
    "text": "Agentic AI\nAgentic AI is a form of AI that emphasizes autonomy. This implies that it is capable of making decisions, taking action, and even learning on its own to accomplish particular objectives. It‚Äôs similar to having a virtual assistant that can reason, think, and adjust to new conditions without continual guidance.\nThere are four main phases to agentic AI operation:\nPerception: It collects information from its surroundings.\nReasoning: It analyses this information to determine what is happening.\nAction: It uses its comprehension to determine what to do.\nLearning: It gains knowledge from experience and criticism as it develops and changes throughout time.\nBecause of this, agentic AI is extremely independent and capable of managing challenging tasks involving logic, problem-solving, and situational adaptation.\n\nUse Cases:\nHealthcare: AI agents can extract important information from massive volumes of patient and medical data to assist physicians in making more educated decisions about patient care. Doctors can concentrate on building relationships with their patients by automating administrative duties and taking clinical notes during patient consultations.\nAutonomous cars: In autonomous cars, an agentic AI system not only recognizes objects but also forecasts how other drivers and pedestrians will behave. It makes decisions in real time, plans routes, and avoids barriers using this information. Agentic AI systems exhibit a degree of ‚Äúintelligent agency‚Äù that surpasses data processing by fusing perception and action, giving them a special capability.\nReal-Time Threat Detection: Agentic AI systems can detect real-time threats by analyzing video streams to identify anomalies like unauthorized access or unusual movement patterns. They can autonomously recognize trespassers and alert security personnel, integrating object detection and behavioural analysis for accurate and timely interventions."
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html#explainable-ai",
    "href": "blog/whats_next_in_ai/index.html#explainable-ai",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "Explainable AI",
    "text": "Explainable AI\nThe goal of the developing field of explainable AI is to provide intuitive explanations for AI model behaviour. The intention is to assist users comprehend how an AI model generates results or makes predictions. An AI system whose core operations are hidden from the user is known as an AI black box. The AI model doesn‚Äôt give any justification for its decisions.\nFor instance, you might not understand why an AI model accurately classifies an image. Scientists and engineers dislike ‚Äúblack boxes.‚Äù They‚Äôre curious about what‚Äôs going on within the box. Explainable AI seeks to reveal mysteries. Explainability strategies aid in demonstrating the rationale behind and possibly the process by which the AI model arrived at its conclusion.\nExplainable AI techniques, such as Grad-CAM, LIME, and occlusion sensitivity, are useful when using models that are not inherently explainable, such as deep learning models. These techniques help users gain confidence in AI decisions and can be useful when comparing the performance of multiple models. The mapping of important features slightly differs between explainability techniques due to the underlying methodology. LIME approximates complex model behaviour using a simpler model, while Grad-CAM uses gradients of classification score to determine the importance of features in the deep learning model. Occlusion sensitivity computes a map of the change in activation when parts of the input are occluded with a mask.\nAs AI technology advances, it is increasingly used to solve real-world problems, and explainability techniques are crucial to ensure trust in the decisions of the model and its functionality.\n\nUse Cases:\nOptimize Clinical Decision Support: The study aimed to improve alert criteria using explainable artificial intelligence (XAI) approaches. Data was extracted from Vanderbilt University Medical Center alerts from 2019 to 2020, and machine learning models were developed to predict user responses. XAI techniques were applied to generate global and local explanations. The final dataset included 2,991‚Äì823 firings with 2689 features. The LightGBM model achieved the highest Area under the ROC Curve, identifying 96 helpful suggestions. A total of 278‚Äì807 firings (9.3%) could have been eliminated. Some suggestions also revealed workflow and education issues. The study aims to identify improvements in clinical decision support (CDS) and improve quality by identifying scenarios where CDS alerts are not accepted due to workflow, education, or staffing issues."
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html#artificial-general-intelligence",
    "href": "blog/whats_next_in_ai/index.html#artificial-general-intelligence",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "Artificial General Intelligence",
    "text": "Artificial General Intelligence\nWhile different people have different definitions of artificial general intelligence (AGI), the most significant aspects of it have already been accomplished by the most recent generation of sophisticated AI large language models, including ChatGPT, LLaMA, Gemini and Claude. One of the key limitations of generative AI, often highlighted by researchers, is what‚Äôs known as ‚ÄòAI hallucinations.‚Äô While these systems are remarkable in generating coherent and contextually appropriate content, there are instances where their outputs can be misleading or outright inaccurate.\nIt would need human-level comprehension and reasoning to fully resolve hallucinations. Consider this: In order to prevent hallucinations, a system would have to:\nHave the ability to achieve various goals and perform tasks in various contexts and environments.\nCapable of handling problems and situations different from those anticipated by its creators.\nCapable of generalizing knowledge to transfer it across different problems or contexts.\nIn essence, these qualities are what we refer to as ‚Äúgeneral intelligence‚Äù. However, arbitrary general intelligence is not possible due to realistic resource constraints. Real-world systems may display limited generality but are more efficient at learning certain tasks, making them somewhat biased towards certain goals and environments. It is unlikely that humans manifest a maximal level of general intelligence, even in relation to their evolutionarily adapted goals and environments.\nAn AI would have attained human-like comprehension and reasoning skills if it could actually overcome hallucinations. By then, we would have something that was close to artificial general intelligence (AGI), not merely a more accurate language model.\n\nUse Cases:\nSmart Homes: The Whisper model has revolutionized speech recognition, delivering exceptional accuracy in multilingual recognition, translation, and language identification. This allows for more intuitive interactions between users and smart home systems, bridging the gap between human language and technology. VALL-E, a text-to-speech synthesis model, uses semi-supervised data to produce personalized, high-quality speech, enhancing communication quality and adaptability. These advancements bring us closer to AGI-powered smart homes that are natural, tailored, and responsive.\nSmart Healthcare: AGI technology can be applied to wearable health devices, enabling real-time data processing to detect vital signs anomalies. This technology can prompt interventions and improve patient care. A Smart Healthcare System integrates IoT and AGI, analyzing data for continuous monitoring and disease prediction."
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html#quantum-ai",
    "href": "blog/whats_next_in_ai/index.html#quantum-ai",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "Quantum AI",
    "text": "Quantum AI\nQuantum AI summaries a selective approach to leverage artificial intelligence, specifically machine learning techniques, to enhance the entire workflow encompassing quantum algorithm development, experimental design, the identification of near-optimal parameters, the transpilation of quantum circuits, error correction during execution, as well as the calibration and design of quantum devices.\n\nUse Cases:\nDrug Discoveries: Artificial intelligence (AI) combines enhanced methods to make drug discovery and development more cost-effective. It can improve drug approval rates, lower costs, and speed up patient access to medications. Quantum computing (QC) can further benefit drug approval and profitability. Pharma leaders are adopting AI and QC technologies for various stages of drug development. In the next 5‚Äì10 years, AI-QC is expected to become standard in the industry. The focus is shifting to scalable solutions addressing larger pharmaceutical issues. Using AI and QC with data analysis will improve understanding of drug processes, streamline experiments, discover new targets, and address pharmaceutical challenges. Developing effective AI-QC strategies can be complex, requiring thorough knowledge of the industry to broaden its applications across the drug life cycle.\nAI researchers intend to focus on developing fundamental technologies that increase the efficiency, interpretability, and adaptability of AI systems. There will be a lot of innovation in the field, ranging from AGI and self-supervised learning to quantum computing and AI ethics. As these technologies become more prevalent in daily life, there will also be a greater focus on the problem of bringing AI systems closer to human values and societal demands."
  },
  {
    "objectID": "blog/whats_next_in_ai/index.html#references",
    "href": "blog/whats_next_in_ai/index.html#references",
    "title": "What‚Äôs next in AI: A Guide to 2025",
    "section": "References:",
    "text": "References:\n\nParr, C.S., Lemay, D.G., Owen, C.L., Woodward-Greene, M.J. and Sun, J., 2021. Multimodal AI to improve agriculture. IT Professional, 23(3), pp.53‚Äì57.\nSwinckels L, de Keijzer A, Loos B, Applegate R, Kookal K, Kalenderian E, Bijwaard H, Bruers J. A personalized periodontitis risk based on nonimage electronic dental records by machine learning. Journal of Dentistry 2025;153:105469\nErik Pounds. (2024, October 22). What Is Agentic AI?\nOgbu, D., Agentic AI in Computer Vision Domain-Recent Advances and Prospects.\nXu, F., Uszkoreit, H., Du, Y., Fan, W., Zhao, D. and Zhu, J., 2019. Explainable AI: A brief survey on history, research areas, approaches and challenges. In Natural language processing and Chinese computing: 8th cCF international conference, NLPCC 2019, dunhuang, China, October 9‚Äì14, 2019, proceedings, part II 8 (pp.¬†563‚Äì574). Springer International Publishing.\nZhang, H. and Ogasawara, K., 2023. Grad-CAM-based explainable artificial intelligence related to medical text processing. Bioengineering, 10(9), p.1070.\nSalih, Ahmed M., et al.¬†A perspective on explainable artificial intelligence methods: SHAP and LIME.Advanced Intelligent Systems (2024): 2400304.\nSiru Liu, Allison B McCoy, Josh F Peterson, Thomas A Lasko, Dean F Sittig, Scott D Nelson, Jennifer Andrews, Lorraine Patterson, Cheryl M Cobb, David Mulherin, Colleen T Morton, Adam Wright, Leveraging explainable artificial intelligence to optimize clinical decision support, Journal of the American Medical Informatics Association,Volume 31, Issue 4, April 2024, Pages 968‚Äì974,\nGoertzel, Ben. Artificial general intelligence: concept, state of the art, and future prospects. Journal of Artificial General Intelligence 5.1 (2014): 1.\nDou, Fei, et al.¬†Towards artificial general intelligence (agi) in the internet of things (iot): Opportunities and challenges. arXiv preprint arXiv:2309.07438 (2023).\nWichert, Andreas. Principles of quantum artificial intelligence: quantum problem solving and machine learning. 2020.\nCova, T., Vitorino, C., Ferreira, M., Nunes, S., Rondon-Villarreal, P., Pais, A. (2022). Artificial Intelligence and Quantum Computing as the Next Pharma Disruptors. arXiv preprint arXiv:2309.07438 (2023). In: Heifetz, A. (eds) Artificial Intelligence in Drug Design. Methods in Molecular Biology, vol 2390. Humana, New York, NY.\n\n\nCitation:\nAnushka Dhiman. (Jan 1, 2025). What‚Äôs next in AI: A Guide to 2025. SOTA Insights Blog: https://anushkadhiman.github.io/blog/whats_next_in_ai"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I‚Äôm Anushka Dhiman, a Computer Vision Engineer and an AI enthusiast interested in the area of AI driven application and researches. I have experience in developing cutting-edge AI systems, including applications in computer vision, natural language processing, and generative AI. I‚Äôve worked on projects such as AI based monitoring and security system in Video Analytics and Survallience.\nMy journey into AI has been fueled by a passion for continuous learning, exploring groundbreaking technologies, and sharing knowledge to empower others in the field."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html",
    "href": "blog/AIResearchHighlightsIn2024/index.html",
    "title": "AI Research Highlights in 2024",
    "section": "",
    "text": "In 2024, the emerging field of artificial intelligence is developing more quickly than anyone could have imagined. It produced innovations that have changed industries, safeguard lives, and gone beyond our wildest expectations. From artificial intelligence (AI) that produces hyper-realistic content to emotionally intelligent machines, AI is advancing beyond our previous understanding of technology and challenging everything we believed to be true.\nLet‚Äôs dive into the most significant researches in AI this year, revealing how they are transforming industries and altering modern life, creation of a sentient artificial intelligence."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#sora",
    "href": "blog/AIResearchHighlightsIn2024/index.html#sora",
    "title": "AI Research Highlights in 2024",
    "section": "Sora",
    "text": "Sora\nIn February 2024, OpenAI introduced Sora, a generative AI model that converts text to video. The model has the ability to simulate the real environment and is trained to produce videos of realistic or imaginative scenes based on text instructions. Sora stands out from other video generation models because it can create exceptional videos a maximum of minute long while adhering to user-provided language instructions.\n\n\nMajor contributions\nTurning visual data into patches: Inspired from LLM, create visual patches which an effective representation for generative models of visual data for highly-scalable and effective representation.\nVideo compression network: This network is used to reduces the dimensionality of visual data and outputs a latent representation that is compressed both temporally and spatially. Moreover, train a corresponding decoder model that maps generated latents back to pixel space.\nSpacetime latent patches: Given a compressed input video, a sequence of spacetime patches is extracted which act as transformer tokens.\nScaling transformers for video generation: A diffusion transformer model is trained by given input noisy patches to predict the clean patches.\nLanguage understanding: Re-captioning technique from DALL¬∑E 330 is used to train text-to-video generation systems. The study also uses GPT to convert user prompts into detailed captions.\n\n\nOutcomes\nPrompting with images and videos: Sora employs a variety of picture and video editing techniques, including as extending videos forward or backward in time, animating static images, and producing flawlessly looping videos.\nImage generation capabilities: Sora generates images by arranging patches of Gaussian noise in a spatial grid with a temporal extent of one frame with variable sizes up to 2048x2048 resolution.\nEmerging simulation capabilities: Video models show emergent capabilities when trained at scale, allowing Sora to simulate physical world aspects without explicit inductive biases for 3D and objects.\n\n\nDiscussion\nSora‚Äôs simulator has limitations, including inaccuracies in modelling basic interactions like glass shattering and incorrect object state changes in eating food, and common failure modes include incoherencies and spontaneous appearances."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#phi-3",
    "href": "blog/AIResearchHighlightsIn2024/index.html#phi-3",
    "title": "AI Research Highlights in 2024",
    "section": "Phi-3",
    "text": "Phi-3\nIn April 2024, Microsoft Introduced Phi-3, the most powerful and economical small language models (SLMs) on the market, superior to models of the same size and next size up in a range of language, reasoning, coding, and math benchmarks.\n\nMajor contributions\nEnhanced Efficiency: Phi-3, despite its smaller parameter size of 3.8 billion, performs relatively as good as larger models, resulting in cost savings for deployment and operation in resource-constrained environments.\nVersatile Applications: Phi-3 is versatile, capable of performing tasks like natural language processing, content creation, data analysis, and automation, reducing administrative burdens and enhancing market research and product development.\nMultimodal Capabilities: Phi-3 Vision‚Äôs multimodal capabilities enable efficient text and image processing, expanding its application scope across various industries while maintaining high performance and reduced computational cost.\n\n\nOutcomes\nPractical Applications: Phi-3 is utilized by organizations for content generation, data analysis, and customer support, enabling the creation of marketing copy, product descriptions, and chatbots.\nScalability and Flexibility: The Phi-3 family offers various model variants, including Phi-3-mini, Phi-3-small, and upcoming larger models, ensuring scalability and flexibility in performance and resource requirements.\n\n\nDiscussion\nLimited Factual Knowledge: Phi-3, due to its smaller parameter size, struggles with tasks requiring extensive factual knowledge, hindering its effectiveness in applications requiring deep understanding, as seen in benchmarks like TriviaQA.\nComplexity of Optimal Data Mixture: The complexity of selecting the optimal data mixture for training can impact the model‚Äôs generalization capabilities and overall effectiveness across various tasks."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#alphafold-3",
    "href": "blog/AIResearchHighlightsIn2024/index.html#alphafold-3",
    "title": "AI Research Highlights in 2024",
    "section": "AlphaFold 3",
    "text": "AlphaFold 3\nIn May 2024, AlphaFold 3, a revolutionary protein folding model, the results show high-accuracy modelling across biomolecular space possibly within a single unified deep-learning network. It was unveiled in 2021 by 2024 Nobel Prize in Chemistry winner Co-founder and CEO of Google DeepMind and Isomorphic Labs Sir Demis Hassabis, and Google DeepMind Director Dr.¬†John Jumper by Demis Hassabis, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences. Their contributions to science have been widely praised and recognized for their work.\n\nMajor contributions\nSubstantial evolution of the AF2 architecture and training procedure: Achieved by both to accommodate more general chemical structures and to improve the data efficiency of learning.\nImproved evoformer: The system reduces the amount of multiple-sequence alignment (MSA) processing by replacing the AF2 evoformer with the simpler pairformer module.\nSpacetime latent patches: Given a compressed input video, a sequence of spacetime patches is extracted which act as transformer tokens.\nA diffusion-based module: It directly predicts the raw atom coordinates with a diffusion module, replacing the AF2 structure module that operated on amino-acid-specific frames and side-chain torsion angles.\n\n\nOutcomes\nSignificantly higher accuracy for protein-ligand interactions as compared to the most advanced docking.\nMuch better accuracy for protein-nucleic acid interactions than nucleic acid-specific predictors, and significantly better accuracy for antibody-antigen prediction than AlphaFold-Multimer v.2.3.\n\n\nDiscussion\nThe AF3 model demonstrates the ability to accurately predict the structure of various biomolecular systems in a unified framework. Although there are still challenges, it shows strong coverage and generalization for all interactions.\nAF3 demonstrates that deep-learning frameworks can reduce data requirements and enhance data impact. Structural modelling will improve due to deep learning and experimental structure determination improvements."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#veo-and-imagen-3",
    "href": "blog/AIResearchHighlightsIn2024/index.html#veo-and-imagen-3",
    "title": "AI Research Highlights in 2024",
    "section": "Veo and Imagen 3",
    "text": "Veo and Imagen 3\nIn May 2024, Google‚Äôs DeepMind introduced Veo and Imagen 3, a most advanced video generation model and highest quality text-to-image model of their research.\nImagen 3 generated image with an input prompt.\n\nMajor contributions\nModel Architecture and Dataset: Veo uses advanced architectures for video generation, focusing on natural language and visual semantics. It generates coherent high-definition videos from text or image prompts. Imagen 3, a refined model, enhances photorealistic image generation by integrating improvements in detail and artifact reduction, likely based on diffusion models. Veo and Imagen 3 are trained on large-scale datasets containing real-world videos and AI-generated imagery with detailed captions, enabling to generate images and videos across various artistic genres and produce more accurate outputs.\n\n\nOutcomes\nFunctionality: Veo is a advanced video generation model that can produce high-definition videos from text or image prompts, supports various cinematic styles, and understands natural language and visual semantics. It can generate coherent video clips from real and AI-generated images, ensuring responsible content use. And, Imagen 3, an upgraded version of Google‚Äôs text-to-image generator, offers advanced editing capabilities, mask-based editing, and customization options for creating detailed, lifelike images from simple text prompts. It can produce images across various styles, including photorealism, impressionism, and anime.\n\n\nDiscussion\nVeo has advanced capabilities but struggles with maintaining consistency in complex scenes, leading to discrepancies in detail and realism. Additionally, Veo may overpromise its capabilities, particularly in producing hyper-realistic animations. Imagen 3 faces challenges in achieving realistic outputs due to hallucinations."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#llama-3",
    "href": "blog/AIResearchHighlightsIn2024/index.html#llama-3",
    "title": "AI Research Highlights in 2024",
    "section": "LLAMA 3",
    "text": "LLAMA 3\nIn July 2024, Meta released Llama3, Herd of Models, that natively support multilinguality, coding, reasoning, and tool usage. This largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens.\n\nMajor contributions\nLarger Dataset and Training: The model was trained on a dataset that is seven times larger than that of Llama 2, encompassing over 15 trillion tokens.\nIncreased Context Length: Llama 3 has doubled the context length from 4K to 8K tokens for both its 8 billion (8B) and 70 billion (70B) parameter models. This allows for improved handling of longer documents and complex queries.\nModel architecture: Llama 3 keeps the decoder-only transformer design but adds a number of improvements, like grouped query attention (GQA) and a tokenizer with a 128K token vocabulary, to improve inference performance and efficiency.\nTrust and Safety Features: Meta has integrated new safety tools such as Llama Guard and Code Shield to filter insecure code outputs, emphasizing responsible AI deployment and usage.\n\n\nOutcomes\nPerformance Metrics: Llama 3 performs with impressive output speeds, with the 8 billion parameter model reaching 117.5 tokens per second and a lower latency of 0.34 seconds, enhancing user experience.\nUsability and Flexibility: Llama 3 is highly adaptable and cost-efficient, suitable for various applications like coding and creative writing. Its configurations allow for fine-tuning, making it suitable for high-throughput tasks.\n\n\nDiscussion\nTechnical and Resource Challenges: Llama 3, with its 405 billion parameters, requires significant computational resources, making it impractical for regular users without hardware capabilities. Despite being designed for speed, larger models may experience latency issues and maintain coherence, affecting user experience.\nUsability and Integration Challenges: Llama 3‚Äôs current version has limited multimodal capabilities, primarily focusing on text, which restricts its applicability in multimodal environments. Additionally, its English-centric dataset may result in suboptimal multilingual performance, hindering global applications."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#sam-2",
    "href": "blog/AIResearchHighlightsIn2024/index.html#sam-2",
    "title": "AI Research Highlights in 2024",
    "section": "SAM 2",
    "text": "SAM 2\nIn July 2024, Meta announced the Segment Anything Model 2 (SAM 2), the next generation of the Meta Segment Anything Model, supporting object segmentation in videos and images.\nSAM 2 model, a promptable segmentation in images and videos\n\nMajor contributions\nUnified Architecture: SAM 2 introduces a unified model architecture that integrates image and video segmentation, simplifying workflows and allowing users to work seamlessly across various visual media.\nEnhanced Neural Network Design: The model‚Äôs refined neural network architecture enhances segmentation, improving accuracy in complex scenes with occlusions or similar colors and textures.\nZero-Shot Learning: SAM 2‚Äôs zero-shot learning feature enables it to segment new objects without explicit retraining, making it versatile and adaptable to diverse visual domains.\n\n\nOutcomes\nImproved Performance Metrics: SAM 2 has set new performance benchmarks, enhancing image segmentation accuracy and reducing user interaction time compared to its predecessor, SAM.\nPromptable Segmentation: In video allows users to specify objects of interest through clicks, bounding boxes, or masks, enhancing user interaction and precision in model output.\nConsistency Across Frames: The model ensures consistent object tracking and segmentation across video frames, crucial for high-quality animation and visual effects applications.\n\n\nDiscussion\nComplexity of Video Segmentation: Video segmentation is complex due to varying object motion, occlusion, lighting changes, and lower quality, which can complicate tracking and segmentation, especially in videos.\nUser Interaction Requirements: SAM 2 is designed for visual segmentation, but still requires user interaction for refinement. Automation could improve mask quality verification and error correction."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#claudes-sonnet",
    "href": "blog/AIResearchHighlightsIn2024/index.html#claudes-sonnet",
    "title": "AI Research Highlights in 2024",
    "section": "Claude‚Äôs Sonnet",
    "text": "Claude‚Äôs Sonnet\nClaude 3.5 Sonnet is a highly proficient model that excels in understanding complex queries and nuanced language, ensuring high-quality, relatable content for a global audience.\n\nMajor contributions\nModel Architecture: Claude 3.5 Sonnet uses a Generative Pre-trained Transformer (GPT) architecture to predict the next word in a sequence of text, enabling effective applications in coding, writing, and visual data interpretation.\nDataset and Training: Claude 3.5 Sonnet, a model trained on vast datasets, enhances natural language understanding by generating human-like text. It supports a large context window of 200,000 tokens and incorporates advanced vision capabilities for image recognition and data visualization.\n\n\nOutcomes\nVisual Processing Capabilities: Claude 3.5 Sonnet excels in image analysis, interpreting visual data with high accuracy, and effectively integrates visual and textual data for comprehensive analyses in industries like retail and finance.\nCoding and Software Development: Claude 3.5 Sonnet enhances coding proficiency and productivity by enabling independent code writing, editing, and execution, while facilitating quick prototyping for app development.\nPerformance Metrics: Claude 3.5 Sonnet has demonstrated superior performance in benchmarks like HumanEval for coding and GPQA for reasoning tasks, showcasing its advanced capabilities.\n\n\nDiscussion\nPerformance Limitations: Claude 3.5 Sonnet, despite improving its language understanding, can misinterpret complex queries and have high error rates in coding tasks, requiring users to debug or refine the code.\nTechnical Challenges: Claude 3.5 Sonnet faces technical challenges, including token limitations and integration issues, affecting processing speed and efficiency for complex tasks and existing workflows."
  },
  {
    "objectID": "blog/AIResearchHighlightsIn2024/index.html#gemini-2",
    "href": "blog/AIResearchHighlightsIn2024/index.html#gemini-2",
    "title": "AI Research Highlights in 2024",
    "section": "Gemini 2",
    "text": "Gemini 2\nGoogle‚Äôs most recent AI model was unveiled as a major development in the business‚Äôs AI capabilities. It is built for what Google calls the ‚Äúagentic era,‚Äù highlighting the model‚Äôs capacity to integrate multimodal functions and carry out activities independently on behalf of users.\n\nMajor contributions\nMultimodal Understanding: Gemini 2.0 is a versatile model that can process and generate various types of data, including text, images, audio, and code, making it more versatile than previous models.\nEnhanced Performance with Low Latency: Gemini 2.0 Flash‚Äôs experimental model enhances performance with improved response times and time to first token (TTFT), improving user experience in real-time applications.\nAgentic Capabilities: The design enhances agentic capabilities, allowing the model to comprehend context, follow complex instructions, and make autonomous decisions based on user prompts, making it a crucial proactive AI assistant.\n\n\nOutcomes\nBenchmark Performance: Gemini 2.0 Flash outperforms in language understanding, visual and multimedia understanding, and coding ability, with a score of 70.7% on the MMMU benchmark. However, it shows slightly lower performance in coding tasks.\nAgentic Performance: Gemini 2.0 demonstrated its agentic performance with a 51.8% score on SWE-bench Verified, demonstrating its capability in real-world tasks like software engineering challenges.\nApplications Across Various Fields: Gemini 2.0‚Äôs versatility allows its use in various fields such as research, business, education, and creative arts, accelerating scientific discovery, automating tasks, and improving decision-making.\n\n\nDiscussion\nGemini 2.0 has faced criticism for generating biased answers and historically inaccurate images, leading to backlash and calls for improvements in performance and accuracy. It also struggles with providing clear, accurate responses to complex topics, potentially causing user frustration and diminishing trust in its capabilities.\nAs we approach 2025, the development of AI presents both exciting opportunities and significant risks. While focusing optimistically on how AI could transform industries, improve decision-making, and solve global problems. Ethicists emphasize responsible AI development, balancing innovation with oversight, to serve humanity‚Äôs best interests. The trajectory of AI depends on navigating competing visions and developing technology and governance structures."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nWhat‚Äôs next in AI: A Guide to 2025\n\n\n\n\n\n\n\n\nJan 1, 2025\n\n\nAnushka Dhiman\n\n\n\n\n\n\n\n\n\n\n\n\nAI Research Highlights in 2024\n\n\n\n\n\n\n\n\nDec 25, 2024\n\n\nAnushka Dhiman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "insights/StatisticsandProbability/ConditionalProb_BayesTheorem.html",
    "href": "insights/StatisticsandProbability/ConditionalProb_BayesTheorem.html",
    "title": "Conditional Probability and Bayes Theorem",
    "section": "",
    "text": "Uptill now in probability, we have discussed the methods of finding the probability of events. If we have two events from the same sample space, does the information about the occurrence of one of the events affect the probability of the other event?"
  },
  {
    "objectID": "insights/StatisticsandProbability/ConditionalProb_BayesTheorem.html#conditional-probability",
    "href": "insights/StatisticsandProbability/ConditionalProb_BayesTheorem.html#conditional-probability",
    "title": "Conditional Probability and Bayes Theorem",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nLet us try to answer this question by taking up a random experiment in which the outcomes are equally likely to occur.\nConsider the experiment of tossing three fair coins. The sample space of the experiment is S = {HHH, HHT, HTH, THH, HTT, THT, TTH, TTT}\nSince the coins are fair, we can assign the probability \\(\\frac{1}{8}\\) to each sample point. Let \\(E\\) be the event ‚Äúat least two heads appear‚Äù and \\(F\\) be the event ‚Äúfirst coin shows tail‚Äù. Then:\n\n\\(E = \\{HHH, HHT, HTH, THH\\}\\)\n\\(F = \\{THH, THT, TTH, TTT\\}\\)\n\nTherefore:\n\nThe probability of \\(E\\) is the sum of the probabilities of its sample points:\n\\[\nP(E) = P(\\{HHH\\}) + P(\\{HHT\\}) + P(\\{HTH\\}) + P(\\{THH\\})\\]\n\\[= \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} = \\frac{4}{8} = \\frac{1}{2}\n\\]\nThe reason for this calculation is that each of these outcomes is equally likely, and there are four outcomes where at least two heads appear.\nThe probability of \\(F\\) is the sum of the probabilities of its sample points:\n\\[\nP(F) = P(\\{THH\\}) + P(\\{THT\\}) + P(\\{TTH\\}) + P(\\{TTT\\})\\]\n\\[= \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} = \\frac{4}{8} = \\frac{1}{2}\n\\]\nThe intersection of \\(E\\) and \\(F\\), denoted \\(E \\cap F\\), contains only the outcome where the first coin shows a tail and at least two heads appear:\n\\[\nE \\cap F = \\{THH\\}\n\\]\nTherefore, the probability of \\(E \\cap F\\) is:\n\\[\nP(E \\cap F) = P(\\{THH\\}) = \\frac{1}{8}\\]\n\nNow, suppose we are given that the first coin shows tail, i.e.¬†F occurs, then what is the probability of occurrence of E? With the information of occurrence of F, we are sure that the cases in which first coin does not result into a tail should not be considered while finding the probability of E. This information reduces our sample space from the set S to its subset F for the event E. In other words, the additional information really amounts to telling us that the situation may be considered as being that of a new random experiment for which the sample space consists of all those outcomes only which are favourable to the occurrence of the event F. Now, the sample point of F which is favourable to event E is THH.\nNow, suppose we are given that the first coin shows tail, i.e.¬†F occurs, then what is the probability of occurrence of E?\nWith the information of occurrence of F, we are sure that the cases in which first coin does not result into a tail should not be considered while finding the probability of E. This information reduces our sample space from the set S to its subset F for the event E.\nIn other words, the additional information really amounts to telling us that the situation may be considered as being that of a new random experiment for which the sample space consists of all those outcomes only which are favourable to the occurrence of the event F.\nNow, the sample point of F which is favourable to event E is THH.\nThus, the probability of \\(E\\) considering \\(F\\) as the sample space is \\(\\frac{1}{4}\\). The probability of \\(E\\) given that the event \\(F\\) has occurred is also \\(\\frac{1}{4}\\). This probability of the event \\(E\\) is called the conditional probability of \\(E\\) given that \\(F\\) has already occurred, and is denoted by \\(P(E|F)\\). Thus,\n\\[\nP(E|F) = \\frac{1}{4}\n\\]\nNote that the elements of \\(F\\) which favor the event \\(E\\) are the common elements of \\(E\\) and \\(F\\), i.e., the sample points of \\(E \\cap F\\). Thus, we can also write the conditional probability of \\(E\\) given that \\(F\\) has occurred as:\n\\[\nP(E|F) = \\frac{\\text{Number of elementary events favorable to } E \\cap F}{\\text{Number of elementary events favorable to } F}\n\\]\nDividing the numerator and the denominator by the total number of elementary events of the sample space, we see that \\(P(E|F)\\) can also be written as:\n\\[\nP(E|F) = \\frac{n(E \\cap F)}{n(F)} = \\frac{n(E \\cap F) / n(S)}{n(F) / n(S)} = \\frac{P(E \\cap F)}{P(F)}\n\\]\nNote that this formula is valid only when \\(P(F) \\neq 0\\), i.e., \\(F \\neq \\phi\\). This is because division by zero is undefined, and if \\(P(F) = 0\\), it means that the event \\(F\\) is impossible, so it cannot be used as a condition for calculating conditional probability.\nThus, we can define the conditional probability as follows:\nIf \\(E\\) and \\(F\\) are two events associated with the same sample space of a random experiment, the conditional probability of the event \\(E\\) given that \\(F\\) has occurred, i.e., \\(P(E|F)\\), is given by:\n\\[\nP(E|F) = \\frac{P(E \\cap F)}{P(F)}\n\\]\nprovided that \\(P(F) \\neq 0\\)."
  },
  {
    "objectID": "insights/StatisticsandProbability/ConditionalProb_BayesTheorem.html#bayes-theorem",
    "href": "insights/StatisticsandProbability/ConditionalProb_BayesTheorem.html#bayes-theorem",
    "title": "Conditional Probability and Bayes Theorem",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\nConsider that there are two bags I and II. Bag I contains 2 white and 3 red balls and Bag II contains 4 white and 5 red balls.\nOne ball is drawn at random from one of the bags.\nWe can find the probability of selecting any of the bags (i.e.¬†1/2 ) or probability of drawing a ball of a particular colour (say white) from a particular bag (say Bag I).\nIn other words, we can find the probability that the ball drawn is of a particular colour, if we are given the bag from which the ball is drawn. But, can we find the probability that the ball drawn is from a particular bag (say Bag II), if the colour of the ball drawn is given?\nHere, we have to find the reverse probability of Bag II to be selected when an event occurred after it is known.\nFamous mathematician, John Bayes‚Äô solved the problem of finding reverse probability by using conditional probability. The formula developed by him is known as ‚ÄòBayes theorem‚Äô which was published posthumously in 1763. Before stating and proving the Bayes‚Äô theorem, let us first take up a definition and some preliminary results.\nA set of events \\(E_1, E_2, \\ldots, E_n\\) is said to represent a partition of the sample space \\(S\\) if:\n\n\\(E_i \\cap E_j = \\phi\\), for \\(i \\neq j\\), where \\(i, j = 1, 2, 3, \\ldots, n\\). This means that the events are pairwise disjoint.\n\\(E_1 \\cup E_2 \\cup \\ldots \\cup E_n = S\\). This means that the events are exhaustive.\n\\(P(E_i) &gt; 0\\) for all \\(i = 1, 2, \\ldots, n\\). This means that each event has a nonzero probability.\n\nIn other words, the events \\(E_1, E_2, \\ldots, E_n\\) represent a partition of the sample space \\(S\\) if they are pairwise disjoint, exhaustive, and have nonzero probabilities.\nAs an example, we see that any nonempty event \\(E\\) and its complement \\(E'\\) form a partition of the sample space \\(S\\) since they satisfy \\(E \\cap E' = \\phi\\) and \\(E \\cup E' = S\\).\nFrom the Venn diagram, one can easily observe that if \\(E\\) and \\(F\\) are any two events associated with a sample space \\(S\\), then the set \\(\\{E \\cap F', E \\cap F, E' \\cap F, E' \\cap F'\\}\\) is a partition of the sample space \\(S\\).\nIt may be mentioned that the partition of a sample space is not unique. There can be several partitions of the same sample space. We shall now prove a theorem known as Theorem of total probability.\nTheorem of Total Probability:\nLet \\(\\{E_1, E_2, \\ldots, E_n\\}\\) be a partition of the sample space \\(S\\), and suppose that each of the events \\(E_1, E_2, \\ldots, E_n\\) has a nonzero probability of occurrence. Let \\(A\\) be any event associated with \\(S\\). Then, the probability of \\(A\\) can be expressed as:\n\\[\nP(A) = P(E_1)P(A|E_1) + P(E_2)P(A|E_2) + \\ldots + P(E_n)P(A|E_n)\n\\]\nAlternatively, using summation notation:\n\\[\nP(A) = \\sum_{i=1}^{n} P(E_i)P(A|E_i)\n\\]\nWe shall now state and prove Bayes‚Äô Theorem.\nBayes‚Äô Theorem:\nIf \\(E_1, E_2, \\ldots, E_n\\) are \\(n\\) non-empty events that constitute a partition of the sample space \\(S\\), i.e., \\(E_1, E_2, \\ldots, E_n\\) are pairwise disjoint and \\(E_1 \\cup E_2 \\cup \\ldots \\cup E_n = S\\), and \\(A\\) is any event of nonzero probability, then:\n\\[\nP(E_i|A) = \\frac{P(E_i)P(A|E_i)}{\\sum_{j=1}^{n} P(E_j)P(A|E_j)}\n\\]\nfor any \\(i = 1, 2, 3, \\ldots, n\\).\nProof:\nBy the formula of conditional probability, we know that:\n\\[\nP(E_i|A) = \\frac{P(A \\cap E_i)}{P(A)}\n\\]\nUsing the multiplication rule of probability, we have:\n\\[\nP(A \\cap E_i) = P(E_i)P(A|E_i)\n\\]\nThus,\n\\[\nP(E_i|A) = \\frac{P(E_i)P(A|E_i)}{P(A)}\n\\]\nBy the theorem of total probability, we know that:\n\\[\nP(A) = \\sum_{j=1}^{n} P(E_j)P(A|E_j)\n\\]\nSubstituting this into the expression for \\(P(E_i|A)\\) gives:\n\\[\nP(E_i|A) = \\frac{P(E_i)P(A|E_i)}{\\sum_{j=1}^{n} P(E_j)P(A|E_j)}\n\\]\nRemark:\nThe following terminology is generally used when Bayes‚Äô theorem is applied. The events \\(E_1, E_2, \\ldots, E_n\\) are called hypotheses. The probability \\(P(E_i)\\) is called the a priori probability of the hypothesis \\(E_i\\). The conditional probability \\(P(E_i|A)\\) is called the a posteriori probability of the hypothesis \\(E_i\\). Bayes‚Äô theorem is also called the formula for the probability of ‚Äúcauses‚Äù. Since the \\(E_i\\)‚Äôs are a partition of the sample space \\(S\\), one and only one of the events \\(E_i\\) occurs (i.e., one of the events \\(E_i\\) must occur and only one can occur). Hence, the above formula gives us the probability of a particular \\(E_i\\) (i.e., a ‚Äúcause‚Äù), given that the event \\(A\\) has occurred. Bayes‚Äô theorem has its applications in a variety of situations, a few of which are illustrated in the following examples.\nLet‚Äôs consider an example,\nBag I contains 3 red and 4 black balls, while another Bag II contains 5 red and 6 black balls. One ball is drawn at random from one of the bags and it is found to be red. We need to find the probability that it was drawn from Bag II.\nTake a shot at solving it by yourself first!!!\n\n\nThe moment of truth: here‚Äôs the solution!\n\nLet \\(E_1\\) be the event of choosing Bag I, \\(E_2\\) the event of choosing Bag II, and \\(A\\) be the event of drawing a red ball. Then:\n\n\\(P(E_1) = P(E_2) = \\frac{1}{2}\\)\n\\(P(A|E_1) = P(\\text{drawing a red ball from Bag I}) = \\frac{3}{7}\\)\n\\(P(A|E_2) = P(\\text{drawing a red ball from Bag II}) = \\frac{5}{11}\\)\n\nNow, the probability of drawing a ball from Bag II, given that it is red, is \\(P(E_2|A)\\). By using Bayes‚Äô theorem, we have:\n\\[\nP(E_2|A) = \\frac{P(E_2)P(A|E_2)}{P(E_1)P(A|E_1) + P(E_2)P(A|E_2)}\n\\]\nSubstituting the given values:\n\\[\nP(E_2|A) = \\frac{\\frac{1}{2} \\times \\frac{5}{11}}{\\frac{1}{2} \\times \\frac{3}{7} + \\frac{1}{2} \\times \\frac{5}{11}}\n\\]\nSimplifying:\n\\[\nP(E_2|A) = \\frac{\\frac{5}{22}}{\\frac{3}{14} + \\frac{5}{22}} = \\frac{\\frac{5}{22}}{\\frac{33 + 35}{154}} = \\frac{\\frac{5}{22}}{\\frac{68}{154}} = \\frac{5}{22} \\times \\frac{154}{68} = \\frac{5 \\times 7}{68} = \\frac{35}{68}\\]"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#overview",
    "href": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#overview",
    "title": "Linear Regression implementation from scratch with Python",
    "section": "Overview",
    "text": "Overview\nLinear regression is a fundamental and powerful model for predicting numeric data from one or more independent variables. This article focuses on implementing linear regression using Python, without delving into the deeper theoretical aspects. Despite the emergence of more complex algorithms like LLM, linear regression remains widely used across various domains due to its effectiveness, interpretability, and extensibility. Understanding linear regression is crucial for building a strong foundation in machine learning, as its core concepts are applied broadly.\nIn a similar manner, I intend to create a playlist that covers other machine learning algorithms from scratch. You can find the list of topics covered in this series.\nLet‚Äôs get started!"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#what-is-linear-regression",
    "href": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#what-is-linear-regression",
    "title": "Linear Regression implementation from scratch with Python",
    "section": "What is Linear regression?",
    "text": "What is Linear regression?\nLinear regression is a statistical method used to model the relationship between a dependent variable (often denoted as ‚Äúy‚Äù) and one or more independent variables (often denoted as ‚Äúx‚Äù).\nThe goal is to find the best fitting line through the data points the minimises the prodiction error.\nImagine you have a scatter plot of data points. Linear regression tries to find a straight line that best represent the relationship between the independent variable and the dependent variable.\nThe line is choosen to minimise the difference between the predicated value and he actual data points. The diference is called the residual error and the goal is to minimise the residual error and hence the best values for model parameters m & c by finding the best fit line.\nThe most common form of linear regression is simple linear regression, which models the relationship between two variables:"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#code-implementation-using-python",
    "href": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#code-implementation-using-python",
    "title": "Linear Regression implementation from scratch with Python",
    "section": "Code Implementation using python",
    "text": "Code Implementation using python\n\nSimple linear regression\nHere is a basic implementation of simple linear regression in Python using the least squares method:\n\nLet‚Äôs break it down step by step:\n\n\n#Importing Libraries\nimport numpy as np # library for numerical operations\n\nclass LinearRegression: \n  # Creted a class named LinearRegression, defining the structure and methods needed to perform linear regression\n\n  def __init__(self):\n    self.slope = None #store the slope (m) of the line \n    self.intercept = None #store the intercept (b) of the line \n\n  def fit(self, X, y):\n    # fit method to compute the slope and intercept of the best-fit line based on the data points X and y.\n\n    n = len(X) \n\n    #calculates the mean of the X values (x_mean) and the mean of the y values (y_mean).\n\n    x_mean = np.mean(X)  \n    y_mean = np.mean(y)\n\n    #initializes two variables, numerator and denominator, to store intermediate results for calculating the slope.\n    numerator = 0 \n    denominator = 0\n\n    #loops over each data point and computes numerator and denominator\n    for i in range(n):\n        numerator += (X[i] - x_mean) * (y[i] - y_mean) # the sum of the product of the deviations X[i] and y[i] from their means\n        denominator += (X[i] - x_mean) ** 2 # the sum of the squared deviations of X[i] from the mean of X\n\n    self.slope = numerator / denominator\n    self.intercept = y_mean - self.slope * x_mean\n\n\n  def predict(self, X): #predict method makes predictions\n\n    \"\"\"For each input value x in the list X, the method computes the corresponding predicted value of y using the formula: y=mx+b\n      where m is the slope and b is the intercept, both of which were calculated during the fitting process.\"\"\"\n\n    y_pred = []\n    for x in X:\n        y_pred.append(self.slope * x + self.intercept)\n    return y_pred\n\n\n\nSlope (m): The slope is computed as the ratio of the numerator to the denominator. This is the formula for the slope of a simple linear regression line:\n\\[ \\text{slope} = \\frac{\\sum(X[i] - x_{\\text{mean}})(y[i] - y_{\\text{mean}})}{\\sum(X[i] - x_{\\text{mean}})^2} \\]\nIntercept (b): The intercept is computed by subtracting the product of the slope and the mean of X from the mean of y:\n\\[ \\text{intercept} = y_{\\text{mean}} - (\\text{slope} \\times x_{\\text{mean}}) \\]\nLet‚Äôs test our code\n\n# Example Data\nX = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 5, 4, 5])\n\n# Create an instance of LinearRegression\nmodel = LinearRegression()\n\n# Fit the model to the data\nmodel.fit(X, y)\n\n# Make predictions\npredictions = model.predict([6, 7, 8])\nprint(predictions)\n\n[5.8, 6.4, 7.0]\n\n\n\nprint(\"slope of the line: \", model.slope)\nprint(\"intercept of the line: \", model.intercept)\n\nslope of the line:  0.6\nintercept of the line:  2.2\n\n\nAfter fitting the model, the slope (m) and intercept (b) of the best-fit line are printed.\nSlope: 0.6 ‚Äî This means that for each increase of 1 in X, y increases by 0.6 on average.\nIntercept: 2.2 ‚Äî This is the predicted value of y when X is 0\n\ny_pred = model.predict(X)\nprint(y_pred)  # Output: [2.8, 3.4, 4.0, 4.6, 5.2]\n\n[2.8000000000000003, 3.4000000000000004, 4.0, 4.6, 5.2]\n\n\nUsing the calculated slope = 0.6 and intercept = 2.2, the predictions for X = [1, 2, 3, 4, 5] are:\nFor X = 1: y = 0.6 * 1 + 2.2 = 2.8\nFor X = 2: y = 0.6 * 2 + 2.2 = 3.4\nFor X = 3: y = 0.6 * 3 + 2.2 = 4.0\nFor X = 4: y = 0.6 * 4 + 2.2 = 4.6\nFor X = 5: y = 0.6 * 5 + 2.2 = 5.2\nThese predicted values ([2.8, 3.4, 4.0, 4.6, 5.2]) as a result.\n\n\nLinear Regression using the Normal Equation\n\n\nModel Equation\nThe model is described as:\n\\[ y = X \\cdot W \\]\nwhere: - X is the matrix of input data (size ( n d ), where ( n ) is the number of samples and ( d ) is the number of features). - y is the vector of output values (size ( n )). - W is the vector of weights (size ( d ), including the intercept).\n\n\nNormal Equation\nThe weights W are computed using the normal equation, which provides a direct way to solve for the optimal weights:\n\\[ W = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y \\]\n\n$ X^T $ is the transpose of X.\n$ (X^T X) $ is the Gram matrix.\nThe inverse of this matrix is calculated and multiplied by \\[ (X^T \\cdot y) \\] to give the optimal weights W.\n\n\nimport numpy as np\n\nclass LinearRegression:\n    def __init__(self):\n        self.W = None #hold the weights of the regression mode\n\n    def fit(self, X, y):\n        n = X.shape[0]  # Number of samples\n        X = np.hstack([np.ones((n, 1)), X])  # Add bias term (1s) as the first column of X\n        self.W = np.linalg.inv(X.T @ X) @ X.T @ y #Normal Equation:\n\n    def predict(self, X):\n        n = X.shape[0]  # Number of samples\n        X = np.hstack([X, np.ones((n, 1))])  # Add bias term\n        return X @ self.W  # Predicted values\n    \n\n\n# Create example input data\nX = np.array([[2, 2], [4, 5], [7, 8]])\ny = np.array([9, 17, 26])\n\n# Fit linear regression model\nlr = LinearRegression()\nlr.fit(X, y)\n\n# Make predictions on new data\nX_new = np.array([[10, 11], [13, 14]])\ny_pred = lr.predict(X_new)\n\n# Print the predictions\nprint(\"Predictions:\", y_pred)  # Expected output: [43.0, 55.0]\n\n# Explanation of the weights:\nprint(\"\\nThe weights W are printed out, which includes:\")\nprint(\"The first value\", lr.W[0], \"is the intercept (bias term).\")\nprint(\"The second value\", lr.W[1], \"corresponds to the weight for the first feature.\")\nprint(\"The third value\", lr.W[2], \"corresponds to the weight for the second feature.\")\n\nPredictions: [35.28429975 44.49290696]\n\nThe weights W are printed out, which includes:\nThe first value 2.8789171100469577 is the intercept (bias term).\nThe second value 1.3595104661934938 corresponds to the weight for the first feature.\nThe third value 1.7100252704129753 corresponds to the weight for the second feature.\n\n\n\n\nImprovement in Linear Regression code\nTo enhance the robustness, efficiency, scalability, and generalization ability of the linear regression model, some improvements are neccesary\n\nAdd Regularization (L2 Regularization)\n\nRegularization helps prevent overfitting. L2 regularization (also known as Ridge Regression) involves adding a penalty term to the cost function that is proportional to the sum of the squared coefficients. The formula for L2 regularization is:\n\\[ \\text{Cost Function} = \\sum(y - \\hat{y})^2 + \\lambda \\sum W^2 \\]\nwhere: - \\[\\lambda\\] (lambda) is the regularization parameter. - W represents the model‚Äôs coefficients.\nTo implement this, we will modify the weight update rule by adding a penalty term to the objective function.\n\nUse Gradient Descent Instead of solving for the weights directly using the Normal Equation (which can be computationally expensive for large datasets), we can use gradient descent to iteratively minimize the cost function. The gradient descent update rule is:\n\n\\[ W = W - \\alpha \\cdot \\nabla J(W) \\]\nwhere: - \\[ \\alpha \\] is the learning rate. - J(W) is the cost function.\nWe will implement a method that updates the coefficients iteratively based on the gradient of the cost function.\n\nimport numpy as np\n\nclass LinearRegressionGD:\n    def __init__(self, learning_rate=0.01, num_iterations=1000, lambda_reg=0):\n        \"\"\"\n        Initializes the linear regression model.\n        :param learning_rate: Learning rate for gradient descent (default: 0.01)\n        :param num_iterations: Number of iterations for gradient descent (default: 1000)\n        :param lambda_reg: Regularization parameter for L2 regularization (default: 0)\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.num_iterations = num_iterations\n        self.lambda_reg = lambda_reg\n        self.W = None\n\n    def _validate_input(self, X, y):\n        \"\"\"\n        Validate input arrays X and y.\n        Ensure they have the same length and are not empty.\n        \"\"\"\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"X and y must have the same number of samples.\")\n        if X.shape[0] == 0:\n            raise ValueError(\"Input arrays X and y cannot be empty.\")\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using gradient descent or the normal equation.\n        :param X: Features matrix (n x d)\n        :param y: Target vector (n x 1)\n        \"\"\"\n        # Validate inputs\n        self._validate_input(X, y)\n        \n        # Add bias term (ones column) to X\n        n = X.shape[0]\n        X = np.hstack([np.ones((n, 1)), X])\n\n        # Initialize weights\n        self.W = np.zeros(X.shape[1])\n\n        # Gradient Descent\n        for _ in range(self.num_iterations):\n            predictions = X @ self.W\n            errors = predictions - y\n            \n            # Compute gradient\n            gradient = (2/n) * X.T @ errors + (2 * self.lambda_reg * self.W)\n            \n            # Update weights\n            self.W -= self.learning_rate * gradient\n\n    def predict(self, X):\n        \"\"\"\n        Make predictions using the learned model.\n        :param X: Features matrix (n x d)\n        :return: Predicted values (n x 1)\n        \"\"\"\n        n = X.shape[0]\n        X = np.hstack([np.ones((n, 1)), X])  # Add bias term\n        return X @ self.W\n\n\n# Example usage:\nX = np.array([[2, 2], [4, 5], [7, 8]])  # Input data\ny = np.array([9, 17, 26])  # Target data\n\n# Create model with L2 regularization (lambda_reg &gt; 0) and gradient descent\nlr = LinearRegressionGD(learning_rate=0.01, num_iterations=1000, lambda_reg=0.1)\n\n# Fit the model to the data\nlr.fit(X, y)\nprint(\"Weights:\", lr.W)\n\n# Make predictions on new data\nX_new = np.array([[10, 11], [13, 14]])\ny_pred = lr.predict(X_new)\nprint(\"Predictions:\", y_pred)\n\nWeights: [2.0109441  1.50918066 1.71595145]\nPredictions: [35.97821669 45.65361304]"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#visualization",
    "href": "insights/StatisticsandProbability/MachineLearning/linear_regression.html#visualization",
    "title": "Linear Regression implementation from scratch with Python",
    "section": "Visualization",
    "text": "Visualization\nLet‚Äôs visualise it on scatter plot, giving a clear picture of how well the regression line fits the data points!\n\nimport matplotlib.pyplot as plt\n\n# Plotting the data and the linear regression model\nplt.scatter(X[:, 0], y, color='blue', label='Training data')\n\n# Plot the predicted values\nplt.scatter(X_new[:, 0], y_pred, color='red', label='Predictions')\n\n# Optionally, plot the regression line for the training data (assuming 2D data for visualization)\n# Generate a range of X values for the line (from the min to max of the training data)\nx_line = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\ny_line = lr.predict(np.column_stack([x_line, x_line]))  # Prediction on the line\nplt.plot(x_line, y_line, color='green', label='Regression line')\n\n# Set labels and title\nplt.xlabel('Feature 1')\nplt.ylabel('Target')\nplt.title('Linear Regression with Gradient Descent')\nplt.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/svm.html#what-is-support-vector-machines-svms",
    "href": "insights/StatisticsandProbability/MachineLearning/svm.html#what-is-support-vector-machines-svms",
    "title": "Support Vector Machine implementation from scratch with Python",
    "section": "What is Support Vector Machines (SVMs)",
    "text": "What is Support Vector Machines (SVMs)\nSupport Vector Machines (SVMs) are a type of machine learning algorithm used for classification and regression analysis. In particular, linear SVMs are used for binary classification problems where the goal is to separate two classes by a hyperplane.\nThe hyperplane is a line that divides the feature space into two regions. The SVM algorithm tries to find the hyperplane that maximizes the margin, which is the distance between the hyperplane and the closest points from each class. The points closest to the hyperplane are called support vectors and play a crucial role in the algorithm‚Äôs optimization process.\nIn linear SVMs, the hyperplane is defined by a linear function of the input features. The algorithm tries to find the optimal values of the coefficients of this function, called weights, that maximize the margin. This optimization problem can be formulated as a quadratic programming problem, which can be efficiently solved using standard optimization techniques.\nIn addition to finding the optimal hyperplane, SVMs can also handle non-linearly separable data by using a kernel trick. This technique maps the input features into a higher-dimensional space, where they might become linearly separable. The SVM algorithm then finds the optimal hyperplane in this transformed feature space, which corresponds to a non-linear decision boundary in the original feature space.\nLinear SVMs have been widely used in many applications, including text classification, image classification, and bioinformatics. They have the advantage of being computationally efficient and easy to interpret. However, they may not perform well in highly non-linearly separable datasets, where non-linear SVMs may be a better choice."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/svm.html#svm-code-implementation-using-python",
    "href": "insights/StatisticsandProbability/MachineLearning/svm.html#svm-code-implementation-using-python",
    "title": "Support Vector Machine implementation from scratch with Python",
    "section": "SVM Code Implementation using python",
    "text": "SVM Code Implementation using python\nHere‚Äôs an example implementation of a Support Vector Machine (SVM) classifier using gradient descent for optimization:\nKey Concepts:\n\nMargin: SVM aims to maximize the margin (distance between the hyperplane and the closest samples from each class).\nRegularization: The regularization parameter (lambda_param) helps control the trade-off between maximizing the margin and minimizing classification error.\nGradient Descent: This is used to iteratively optimize the weights and bias.\n\n\nimport numpy as np\n\nclass SVM:\n    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n        self.lr = learning_rate\n        self.lambda_param = lambda_param\n        self.n_iters = n_iters\n        self.w = None\n        self.b = None\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        y_ = np.where(y &lt;= 0, -1, 1)\n        self.w = np.zeros(n_features)\n        self.b = 0\n\n        # Gradient descent\n        for _ in range(self.n_iters):\n            for idx, x_i in enumerate(X):\n                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) &gt;= 1\n                if condition:\n                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n                else:\n                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n                    self.b -= self.lr * y_[idx]\n\n    def predict(self, X):\n        linear_output = np.dot(X, self.w) - self.b\n        return np.sign(linear_output)\n\n\n\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Assuming the SVM class is defined above and already imported\n\n# Generate synthetic data with 2 classes\nX, y = datasets.make_blobs(n_samples=100, centers=2, random_state=42)\ny = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1 instead of 0 and 1\n\n# Split the data into training and test sets (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Instantiate and train the SVM model\nsvm = SVM()  # You can add parameters here like learning_rate, lambda_param, etc.\nsvm.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = svm.predict(X_test)\n\n# Evaluate the model by calculating accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\nAccuracy: 1.0\n\n\nIn this case, since the data is simple and linearly separable, the SVM classifier likely achieves a perfect accuracy of 100%. However, for more complex data, you may see lower accuracy depending on the dataset‚Äôs difficulty.\nHere‚Äôs key thing to note, we can fine-tune hyperparameters like learning rate (learning_rate), regularization strength (lambda_param), and the number of iterations (n_iters) to improve performance."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/svm.html#visualization",
    "href": "insights/StatisticsandProbability/MachineLearning/svm.html#visualization",
    "title": "Support Vector Machine implementation from scratch with Python",
    "section": "Visualization",
    "text": "Visualization\n\nimport matplotlib.pyplot as plt\n\n# Plot the training data\nplt.figure(figsize=(8, 6))\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='bwr', marker='o', label='Training data')\n\n# Plot the decision boundary\nxx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 100),\n                     np.linspace(X[:, 1].min(), X[:, 1].max(), 100))\n\n# Compute the decision function values on the grid\nZ = np.dot(np.c_[xx.ravel(), yy.ravel()], svm.w) - svm.b\nZ = Z.reshape(xx.shape)\n\n# Plot the contour of the decision boundary\nplt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='k')\n\n# Plot the support vectors (samples closest to the decision boundary)\nsupport_vectors = np.where(np.abs(np.dot(X_train, svm.w) - svm.b) &lt;= 1)[0]\nplt.scatter(X_train[support_vectors, 0], X_train[support_vectors, 1], c='yellow', marker='x', s=100, label='Support Vectors')\n\n# Show plot with appropriate labels and legend\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.title('SVM Classifier with Decision Boundary and Support Vectors')\nplt.legend(loc='best')\nplt.show()\n\n\n\n\n\n\n\n\nThe resultant plot shows:\n\nBlue and Red dots representing the two different classes.\nA black line representing the decision boundary that separates the classes.\nYellow ‚ÄòX‚Äô markers for the support vectors, which are the critical data points closest to the decision boundary."
  },
  {
    "objectID": "insights/StatisticsandProbability/Probability.html#overview",
    "href": "insights/StatisticsandProbability/Probability.html#overview",
    "title": "Probability",
    "section": "Overview",
    "text": "Overview\nProbability is defined as a quantitative measure of uncertainty ‚Äì a numerical value that conveys the strength of our belief in the occurrence of an event.\nThe probability of an event is always a number between 0 and 1 both 0 and 1 inclusive.\nIf an event‚Äôs probability is nearer to 1, the higher is the likelihood that the event will occur; the closer the event‚Äôs probability to 0, the smaller is the likelihood that the event will occur.\nIf the event cannot occur, its probability is 0. If it must occur (i.e., its occurrence is certain), its probability is 1."
  },
  {
    "objectID": "insights/StatisticsandProbability/Probability.html#random-experiment",
    "href": "insights/StatisticsandProbability/Probability.html#random-experiment",
    "title": "Probability",
    "section": "Random experiment",
    "text": "Random experiment\nAn experiment is random means that the experiment has more than one possible outcome and it is not possible to predict with certainty which outcome that will be. For instance, in an experiment of tossing an ordinary coin, it can be predicted with certainty that the coin will land either heads up or tails up, but it is not known for sure whether heads or tails will occur. If a die is thrown once, any of the six numbers, i.e., 1, 2, 3, 4, 5, 6 may turn up, not sure which number will come up.\n(i) Outcome A possible result of a random experiment is called its outcome for example if the experiment consists of tossing a coin twice, some of the outcomes are HH, HT etc.\n(ii) Sample Space A sample space is the set of all possible outcomes of an experiment. In fact, it is the universal set S pertinent to a given experiment. The sample space for the experiment of tossing a coin twice is given by S = {HH, HT, TH, TT}\nThe sample space for the experiment of drawing a card out of a deck is the set of all cards in the deck."
  },
  {
    "objectID": "insights/StatisticsandProbability/Probability.html#event",
    "href": "insights/StatisticsandProbability/Probability.html#event",
    "title": "Probability",
    "section": "Event",
    "text": "Event\nAn event is a subset of a sample space S. For example, the event of drawing an ace from a deck is A = {Ace of Heart, Ace of Club, Ace of Diamond, Ace of Spade}\n\nEvent A or B\nIf A and B are two events associated with same sample space, then the event A or B is same as the event A ‚à™ B and contains all those elements which are either in A or in B or in both.\nFurther more, P(A‚à™B) denotes the probability that A or B (or both) will occur.\n\n\nEvent A and B\nIf A and B are two events associated with a sample space, then the event A and B is same as the event A‚à© B and contains all those elements which are common to both A and B.\nFurther more, P (A ‚à© B) denotes the probability that both A and B will simultaneously occur.\n\n\nThe Event A but not B (Difference A ‚Äì B)\nAn event A ‚Äì B is the set of all those elements of the same space S which are in A but not in B, i.e.,\nA ‚Äì B = A ‚à© B‚Äô.\n\n\nMutually exclusive\nTwo events A and B of a sample space S are mutually exclusive if the occurrence of any one of them excludes the occurrence of the other event.\nHence, the two events A and B cannot occur simultaneously, and thus P(A‚à©B) = 0.\nConsider the experiment of throwing a die once.\nE = The event of getting a even number.\nF = The event of getting an odd number\nThe events are mutually exclusive events because E ‚à© F = œÜ.\nNote that For a given sample space, there may be two or more mutually exclusive events.\n\n\nExhaustive events\nIf \\(E_1, E_2, \\ldots, E_n\\) are \\(n\\) events of a sample space \\(S\\) and if\n\\[\nE_1 \\cup E_2 \\cup E_3 \\cup \\ldots \\cup E_n = \\bigcup_{i=1}^{n} E_i\n\\]\nthen \\(E_1, E_2, \\ldots, E_n\\) are called exhaustive events.\nIn other words, events E1 , E2 , ‚Ä¶, En of a sample space S are said to be exhaustive if atleast one of them necessarily occur whenever the experiment is performed.\nLet‚Äôs consider the example of rolling a die.\nWe have a sample space S = {1, 2, 3, 4, 5, 6}.\nWe define the two events\nEvent A : a number less than or equal to 4 appears\nEvent B : a number greater than or equal to 4 appears\nwhich implies A : {1, 2, 3, 4}, B = {4, 5, 6}\nHence, A ‚à™ B = {1, 2, 3, 4, 5, 6} = S\nSuch events A and B are called exhaustive events."
  },
  {
    "objectID": "insights/StatisticsandProbability/Probability.html#classical-definition",
    "href": "insights/StatisticsandProbability/Probability.html#classical-definition",
    "title": "Probability",
    "section": "Classical definition",
    "text": "Classical definition\nIf all of the outcomes of a sample space are equally likely, then the probability that an event will occur is equal to the ratio :\n\\(\\frac{\\text{Number of favourable outcomes}}{\\text{Total number of outcomes in the sample space}}\\)\nSuppose that an event E can happen in h ways out of a total of n possible equally likely ways.\nThen, the classical probability of occurrence of the event is denoted by\n\\[\nP(E) = \\frac{\\text{Number of favourable outcomes}}{\\text{Total number of outcomes in the sample space}}\n\\]\nThe probability of non-occurrence of the event \\(E\\) is denoted by \\(P(\\text{not }E)\\) or \\(P(E')\\), where \\(E'\\) is the complement of \\(E\\). It is calculated as:\n\\[\nP(\\text{not }E) = 1 - P(E)\n\\]\nThus,\n\\[\nP(E) + P(\\text{not }E) = 1\n\\]\nThe event ‚Äúnot \\(E\\)‚Äù is denoted by \\(E'\\) (complement of \\(E\\)).\nTherefore,\n\\[\nP(E') = 1 - P(E)\n\\]"
  },
  {
    "objectID": "insights/StatisticsandProbability/Probability.html#axiomatic-approach-to-probability",
    "href": "insights/StatisticsandProbability/Probability.html#axiomatic-approach-to-probability",
    "title": "Probability",
    "section": "Axiomatic approach to probability",
    "text": "Axiomatic approach to probability\nLet S be the sample space of a random experiment.\nThe probability P is a real valued function whose domain is the power set of S, i.e., P (S)\nand range is the interval [0, 1] i.e.¬†P : P (S) ‚Üí [0, 1]\nsatisfying the following axioms.\n\nFor any event E, \\[ 0 \\leq P(E) \\leq 1\\]\nP(S) = 1\nIf E and F are mutually exclusive events, then P (E ‚à™ F) = P (E) + P (F).\n\nIt follows from (iii) that P (œÜ) = 0.\nLet \\(S\\) be a sample space containing elementary outcomes \\(w_1, w_2, \\ldots, w_n\\), i.e.,\n\\[\nS = \\{w_1, w_2, \\ldots, w_n\\}\n\\]\nIt follows from the axiomatic definition of probability that:\n\n\\(0 \\leq P(w_i) \\leq 1\\) for each \\(w_i \\in S\\)\n\\(P(w_1) + P(w_2) + \\ldots + P(w_n) = 1\\)\nFor any event \\(A\\) containing elementary events \\(w_i\\), the probability of \\(A\\) is the sum of the probabilities of these elementary events. Thus, if \\(A = \\{w_i\\}\\), then \\(P(A) = P(w_i)\\). However, if \\(A\\) contains multiple elementary events, say \\(A = \\{w_1, w_2, \\ldots, w_k\\}\\), then:\n\n\\[\nP(A) = P(w_1) + P(w_2) + \\ldots + P(w_k)\n\\]\nLet‚Äôs consider a fair coin is tossed once P (H) = P (T) = \\(\\frac{1}{2}\\) satisfies the three axioms of probability.\nNow suppose the coin is not fair and has double the chances of falling heads up as compared to the tails, then P (H) = \\(\\frac{2}{3}\\) and P (T) = \\(\\frac{1}{3}\\) .\nThis assignment of probabilities are also valid for H and T as these satisfy the axiomatic definitions."
  },
  {
    "objectID": "insights/StatisticsandProbability/Probability.html#probabilities-of-equally-likely-outcomes",
    "href": "insights/StatisticsandProbability/Probability.html#probabilities-of-equally-likely-outcomes",
    "title": "Probability",
    "section": "Probabilities of equally likely outcomes:",
    "text": "Probabilities of equally likely outcomes:\nLet a sample space of an experiment be \\(S = \\{w_1, w_2, \\ldots, w_n\\}\\) and suppose that all the outcomes are equally likely to occur, i.e., the chance of occurrence of each simple event must be the same. Thus,\n\\[\nP(w_i) = p \\text{ for all } w_i \\in S, \\text{ where } 0 \\leq p \\leq 1\n\\]\nSince the sum of probabilities of all outcomes must equal 1:\n\\[\n\\sum_{i=1}^{n} P(w_i) = 1\n\\]\nThis implies:\n\\[\np + p + \\ldots + p \\text{ (n times)} = 1\n\\]\n\\[\n\\Rightarrow np = 1\n\\]\nTherefore,\n\\[\np = \\frac{1}{n}\n\\]\nLet \\(S\\) be the sample space and \\(E\\) be an event, such that \\(n(S) = n\\) and \\(n(E) = m\\). If each outcome is equally likely, then it follows that:\n\\[\nP(E) = \\frac{m}{n} = \\frac{\\text{Number of outcomes favourable to } E}{\\text{Total number of possible outcomes}}\\]"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html",
    "title": "K Mean implementation from scratch with Python",
    "section": "",
    "text": "K-means clustering is a popular unsupervised machine learning algorithm used for grouping similar data points into k - clusters.\nThe goal here is to partition a given dataset into k (predefined) clusters.\nThe k-means algorithm works by first randomly initializing k cluster centers, one for each cluster. Each data point in the dataset is then assigned to the nearest cluster center based on their distance. The distance metric used is typically Euclidean distance, but other distance measures such as Manhattan distance or cosine similarity can also be used.\nAfter all the data points have been assigned to a cluster, the algorithm calculates the new mean for each cluster by taking the average of all the data points assigned to that cluster. These new means become the new cluster centers. The algorithm then repeats the assignment and mean calculation steps until the cluster assignments no longer change or until a maximum number of iterations is reached.\nThe final output of the k-means algorithm is a set of k clusters, where each cluster contains the data points that are most similar to each other based on the distance metric used. The algorithm is commonly used in various fields such as image segmentation, market segmentation, and customer profiling."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#code",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#code",
    "title": "K Mean implementation from scratch with Python",
    "section": "Code",
    "text": "Code\nHere‚Äôs an implementation of k-means clustering algorithm in Python from scratch:\nKey Concepts: - Centroids: The central point of each cluster. - Euclidean Distance: The distance measure used to calculate the proximity of data points to the centroids. - Convergence: The process of the centroids stabilizing, indicating that the clustering has been achieved.\n\nimport numpy as np\n\nclass KMeans:\n    def __init__(self, k, max_iterations=100):\n        self.k = k\n        self.max_iterations = max_iterations\n        \n    def fit(self, X):\n        # Initialize centroids randomly\n        self.centroids = X[np.random.choice(range(len(X)), self.k, replace=False)]\n\n        # Iterative Process: The algorithm runs for a maximum number of iterations (max_iterations)\n        for i in range(self.max_iterations):\n            # Assign each data point to the nearest centroid\n            cluster_assignments = []\n            for j in range(len(X)):\n                distances = np.linalg.norm(X[j] - self.centroids, axis=1) # compute the Euclidean distance to all centroids and assign the data point to the centroid that is closest.\n                cluster_assignments.append(np.argmin(distances)) # \n            \n            # Update centroids\n            for k in range(self.k):\n                cluster_data_points = X[np.where(np.array(cluster_assignments) == k)]\n                if len(cluster_data_points) &gt; 0:\n                    self.centroids[k] = np.mean(cluster_data_points, axis=0)\n            \n            # Check for convergence\n            # If the centroids stop changing (i.e., the current centroids are equal to the previous centroids), the algorithm terminates early as it has converged. \n            if i &gt; 0 and np.array_equal(self.centroids, previous_centroids):\n                break\n            \n            # Update previous centroids\n            previous_centroids = np.copy(self.centroids)\n        \n        # Store the final cluster assignments\n        self.cluster_assignments = cluster_assignments\n    \n    def predict(self, X):\n        # Assign each data point to the nearest centroid\n        cluster_assignments = []\n        for j in range(len(X)):\n            distances = np.linalg.norm(X[j] - self.centroids, axis=1) # Compute the distance from each point to the centroids using Euclidean distance\n            cluster_assignments.append(np.argmin(distances)) # Assign each new data point to the closest centroid\n        \n        return cluster_assignments\n\nLet‚Äôs test our code,\nHere is an example of how you would use the KMeans class to fit the model and make predictions:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create some sample data (2D points)\nX = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n\n# Initialize the KMeans class with k=2 clusters\nkmeans = KMeans(k=2)\n\n# Fit the model to the data\nkmeans.fit(X)\n\n# Print the final centroids\nprint(\"Final Centroids:\\n\", kmeans.centroids)\n\n# Make predictions on the same data\npredictions = kmeans.predict(X)\nprint(\"Cluster Assignments:\", predictions)\n\nFinal Centroids:\n [[2 3]\n [2 0]]\nCluster Assignments: [0, 0, 1, 0, 0, 1]"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/knn.html#what-is-knn",
    "href": "insights/StatisticsandProbability/MachineLearning/knn.html#what-is-knn",
    "title": "K-Nearest implementation from scratch with Python",
    "section": "What is KNN?",
    "text": "What is KNN?\nK-Nearest Neighbors (KNN) which is a simple, yet effective, algorithm used for classification (and regression) tasks.\nIt is a classification algorithm that assigns a class label to a data point based on the class labels of its k nearest neighbors in the training set. It is a non-parametric algorithm, which means that it does not make any assumptions about the distribution of the data.\nThe KNN algorithm works as follows:\n\nChoose a value of k (the number of nearest neighbors to consider).\nFor each data point in the test set, compute its distance to all data points in the training set.\nSelect the k nearest neighbors based on their distances.\nAssign the class label that appears most frequently among the k nearest neighbors to the test point.\n\nThe distance between two data points can be computed using a distance metric such as Euclidean distance, Manhattan distance, or Minkowski distance. The choice of distance metric depends on the nature of the data and the problem at hand.\nOne important aspect of the KNN algorithm is the choice of the value of k. A small value of k will result in a more flexible decision boundary that can capture complex patterns in the data, but may also lead to overfitting. A large value of k will result in a smoother decision boundary that may not capture fine details in the data, but is less prone to overfitting. The value of k is typically chosen using cross-validation.\nKNN can also be used for regression tasks, where the goal is to predict a continuous value instead of a class label. In this case, the predicted value for a test point is the average of the values of its k nearest neighbors in the training set."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/knn.html#visualization",
    "href": "insights/StatisticsandProbability/MachineLearning/knn.html#visualization",
    "title": "K-Nearest implementation from scratch with Python",
    "section": "Visualization",
    "text": "Visualization\n\n# Plot the training data\nplt.figure(figsize=(8, 6))\nplt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, cmap=plt.cm.Paired, marker='o', label='Train Data')\n\n# Plot the test data\nplt.scatter(X_test_2d[:, 0], X_test_2d[:, 1], c=y_pred, cmap=plt.cm.Paired, marker='x', label='Test Data Predictions')\n\n# Add title and labels\nplt.title('KNN Classifier on Iris Dataset (PCA Reduced to 2D)')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.legend()\nplt.colorbar()  # Add a color bar to represent different classes\nplt.show()\n\n\n\n\n\n\n\n\nSince the Iris dataset is 4-dimensional, it is reduced to 2 dimensions using Principal Component Analysis (PCA) for visualization purposes. PCA helps to visualize high-dimensional data in a 2D space while maintaining as much variance as possible.\nX_train_2d and X_test_2d are the transformed 2D representations of the training and test data.\nThe matplotlib library is used to plot the 2D points.\n\nTraining Data: Circles represent the training data points, colored according to their class label.\nTest Data: Crosses represent the test data points, and their color reflects the predicted class labels based on the k-NN classifier.\n\nThe decision boundaries can be observed based on how the different classes are distributed in the 2D space.\nThe things to note here are:\n\nThe plot helps us see how well the KNN classifier has classified the test data based on the training data.\nThe PCA is used here to make the data 2D for visualization. However, the actual classification is done in the 4-dimensional feature space of the original Iris dataset."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#k-means",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#k-means",
    "title": "K Mean implementation from scratch with Python",
    "section": "K-means",
    "text": "K-means\nK-means clustering is a popular unsupervised machine learning algorithm used for grouping similar data points into k - clusters.\nThe goal here is to partition a given dataset into k (predefined) clusters.\nThe k-means algorithm works by first randomly initializing k cluster centers, one for each cluster. Each data point in the dataset is then assigned to the nearest cluster center based on their distance. The distance metric used is typically Euclidean distance, but other distance measures such as Manhattan distance or cosine similarity can also be used.\nAfter all the data points have been assigned to a cluster, the algorithm calculates the new mean for each cluster by taking the average of all the data points assigned to that cluster. These new means become the new cluster centers. The algorithm then repeats the assignment and mean calculation steps until the cluster assignments no longer change or until a maximum number of iterations is reached.\nThe final output of the k-means algorithm is a set of k clusters, where each cluster contains the data points that are most similar to each other based on the distance metric used. The algorithm is commonly used in various fields such as image segmentation, market segmentation, and customer profiling."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#visualization",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#visualization",
    "title": "K Mean implementation from scratch with Python",
    "section": "Visualization",
    "text": "Visualization\n\n\n\n# Visualize the clusters and centroids\nplt.scatter(X[:, 0], X[:, 1], c=predictions, cmap='viridis')\nplt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1], s=200, c='red', marker='X')  # Plot centroids\nplt.title('K-Means Clustering')\nplt.show()\n\n\n\n\n\n\n\n\nLet‚Äôs break down this example,\n\nData: The array X contains six 2D data points. These are the points that we want to cluster into two groups.\nModel Initialization: We initialize the KMeans object with k=2 (meaning we want two clusters).\nFitting: We then fit the model to the data with the fit method, which will iteratively find two clusters and update the centroids.\nPredictions: The predict method is used to assign each data point to one of the two clusters.\nVisualization: We plot the data points and the final centroids (shown as red ‚ÄòX‚Äô markers) to visually confirm that the KMeans algorithm has correctly clustered the data."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#what-is-k-means-clustering",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#what-is-k-means-clustering",
    "title": "K Mean implementation from scratch with Python",
    "section": "What is K-means clustering?",
    "text": "What is K-means clustering?\nK-means clustering is a popular unsupervised machine learning algorithm used for grouping similar data points into k - clusters.\nThe goal here is to partition a given dataset into k (predefined) clusters.\nThe k-means algorithm works by first randomly initializing k cluster centers, one for each cluster. Each data point in the dataset is then assigned to the nearest cluster center based on their distance. The distance metric used is typically Euclidean distance, but other distance measures such as Manhattan distance or cosine similarity can also be used.\nAfter all the data points have been assigned to a cluster, the algorithm calculates the new mean for each cluster by taking the average of all the data points assigned to that cluster. These new means become the new cluster centers. The algorithm then repeats the assignment and mean calculation steps until the cluster assignments no longer change or until a maximum number of iterations is reached.\nThe final output of the k-means algorithm is a set of k clusters, where each cluster contains the data points that are most similar to each other based on the distance metric used. The algorithm is commonly used in various fields such as image segmentation, market segmentation, and customer profiling."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#optimise-kmean-algorithm",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#optimise-kmean-algorithm",
    "title": "K Mean implementation from scratch with Python",
    "section": "Optimise KMean Algorithm",
    "text": "Optimise KMean Algorithm\nHere are some ways to optimize the k-means clustering algorithm:\nRandom initialization of centroids: Instead of initializing the centroids using the first k data points, we can randomly initialize them to improve the convergence of the algorithm. This can be done by selecting k random data points from the input dataset as the initial centroids.\nEarly stopping: We can stop the k-means algorithm if the cluster assignments and centroids do not change after a certain number of iterations. This helps to avoid unnecessary computation.\nHere‚Äôs an optimized version of the k-means clustering algorithm that implements these optimizations:\n\nimport numpy as np\n\nclass KMeans:\n    def __init__(self, k=3, max_iters=100, tol=1e-4):\n        self.k = k\n        self.max_iters = max_iters\n        self.tol = tol\n    \n    def fit(self, X):\n        # Initialize centroids randomly\n        self.centroids = X[np.random.choice(X.shape[0], self.k, replace=False)]\n        \n        # Iterate until convergence or maximum number of iterations is reached\n        for i in range(self.max_iters):\n            # Assign each data point to the closest centroid\n            distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n            cluster_assignments = np.argmin(distances, axis=1)\n            \n            # Update the centroids based on the new cluster assignments\n            new_centroids = np.array([np.mean(X[np.where(cluster_assignments == j)], axis=0) \n                                      for j in range(self.k)])\n            \n            # Check for convergence\n            if np.linalg.norm(new_centroids - self.centroids) &lt; self.tol:\n                break\n                \n            self.centroids = new_centroids\n    \n    def predict(self, X):\n        # Assign each data point to the closest centroid\n        distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n        cluster_assignments = np.argmin(distances, axis=1)\n        \n        return cluster_assignments\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample data (2D)\nX = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n\n# Initialize KMeans with 2 clusters\nkmeans = KMeans(k=2)\n\n# Train the model\nkmeans.fit(X)\n\n# Get the cluster assignments for the data points\ncluster_assignments = kmeans.predict(X)\n\n# Plot the data points, colored by their cluster assignment\nplt.scatter(X[:, 0], X[:, 1], c=cluster_assignments, cmap='viridis')\n\n# Plot the centroids\nplt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1], c='red', marker='X', s=200)\n\nplt.show()\n\n\n\n\n\n\n\n\nIn the example above:\n\nData points are plotted with colors corresponding to their assigned clusters.\nCentroids are marked with red ‚ÄúX‚Äù symbols, showing the final positions of the centroids after training."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#code-implementation",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#code-implementation",
    "title": "K Mean implementation from scratch with Python",
    "section": "Code Implementation",
    "text": "Code Implementation\nHere‚Äôs an implementation of k-means clustering algorithm in Python from scratch:\nKey Concepts: - Centroids: The central point of each cluster. - Euclidean Distance: The distance measure used to calculate the proximity of data points to the centroids. - Convergence: The process of the centroids stabilizing, indicating that the clustering has been achieved.\n\nimport numpy as np\n\nclass KMeans:\n    def __init__(self, k, max_iterations=100):\n        self.k = k\n        self.max_iterations = max_iterations\n        \n    def fit(self, X):\n        # Initialize centroids randomly\n        self.centroids = X[np.random.choice(range(len(X)), self.k, replace=False)]\n\n        # Iterative Process: The algorithm runs for a maximum number of iterations (max_iterations)\n        for i in range(self.max_iterations):\n            # Assign each data point to the nearest centroid\n            cluster_assignments = []\n            for j in range(len(X)):\n                distances = np.linalg.norm(X[j] - self.centroids, axis=1) # compute the Euclidean distance to all centroids and assign the data point to the centroid that is closest.\n                cluster_assignments.append(np.argmin(distances)) # \n            \n            # Update centroids\n            for k in range(self.k):\n                cluster_data_points = X[np.where(np.array(cluster_assignments) == k)]\n                if len(cluster_data_points) &gt; 0:\n                    self.centroids[k] = np.mean(cluster_data_points, axis=0)\n            \n            # Check for convergence\n            # If the centroids stop changing (i.e., the current centroids are equal to the previous centroids), the algorithm terminates early as it has converged. \n            if i &gt; 0 and np.array_equal(self.centroids, previous_centroids):\n                break\n            \n            # Update previous centroids\n            previous_centroids = np.copy(self.centroids)\n        \n        # Store the final cluster assignments\n        self.cluster_assignments = cluster_assignments\n    \n    def predict(self, X):\n        # Assign each data point to the nearest centroid\n        cluster_assignments = []\n        for j in range(len(X)):\n            distances = np.linalg.norm(X[j] - self.centroids, axis=1) # Compute the distance from each point to the centroids using Euclidean distance\n            cluster_assignments.append(np.argmin(distances)) # Assign each new data point to the closest centroid\n        \n        return cluster_assignments\n\nLet‚Äôs test our code,\nHere is an example of how you would use the KMeans class to fit the model and make predictions:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create some sample data (2D points)\nX = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n\n# Initialize the KMeans class with k=2 clusters\nkmeans = KMeans(k=2)\n\n# Fit the model to the data\nkmeans.fit(X)\n\n# Print the final centroids\nprint(\"Final Centroids:\\n\", kmeans.centroids)\n\n# Make predictions on the same data\npredictions = kmeans.predict(X)\nprint(\"Cluster Assignments:\", predictions)\n\nFinal Centroids:\n [[2 3]\n [2 0]]\nCluster Assignments: [0, 0, 1, 0, 0, 1]"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/k_means.html#k-mean-algorithm-optimization",
    "href": "insights/StatisticsandProbability/MachineLearning/k_means.html#k-mean-algorithm-optimization",
    "title": "K Mean implementation from scratch with Python",
    "section": "K-Mean Algorithm Optimization",
    "text": "K-Mean Algorithm Optimization\nHere are some ways to optimize the k-means clustering algorithm:\nRandom initialization of centroids: Instead of initializing the centroids using the first k data points, we can randomly initialize them to improve the convergence of the algorithm. This can be done by selecting k random data points from the input dataset as the initial centroids.\nEarly stopping: We can stop the k-means algorithm if the cluster assignments and centroids do not change after a certain number of iterations. This helps to avoid unnecessary computation.\nHere‚Äôs an optimized version of the k-means clustering algorithm that implements these optimizations:\n\nimport numpy as np\n\nclass KMeans:\n    def __init__(self, k=3, max_iters=100, tol=1e-4):\n        self.k = k\n        self.max_iters = max_iters\n        self.tol = tol\n    \n    def fit(self, X):\n        # Initialize centroids randomly\n        self.centroids = X[np.random.choice(X.shape[0], self.k, replace=False)]\n        \n        # Iterate until convergence or maximum number of iterations is reached\n        for i in range(self.max_iters):\n            # Assign each data point to the closest centroid\n            distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n            cluster_assignments = np.argmin(distances, axis=1)\n            \n            # Update the centroids based on the new cluster assignments\n            new_centroids = np.array([np.mean(X[np.where(cluster_assignments == j)], axis=0) \n                                      for j in range(self.k)])\n            \n            # Check for convergence\n            if np.linalg.norm(new_centroids - self.centroids) &lt; self.tol:\n                break\n                \n            self.centroids = new_centroids\n    \n    def predict(self, X):\n        # Assign each data point to the closest centroid\n        distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n        cluster_assignments = np.argmin(distances, axis=1)\n        \n        return cluster_assignments\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample data (2D)\nX = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n\n# Initialize KMeans with 2 clusters\nkmeans = KMeans(k=2)\n\n# Train the model\nkmeans.fit(X)\n\n# Get the cluster assignments for the data points\ncluster_assignments = kmeans.predict(X)\n\n# Plot the data points, colored by their cluster assignment\nplt.scatter(X[:, 0], X[:, 1], c=cluster_assignments, cmap='viridis')\n\n# Plot the centroids\nplt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1], c='red', marker='X', s=200)\n\nplt.show()\n\n\n\n\n\n\n\n\nIn the example above:\n\nData points are plotted with colors corresponding to their assigned clusters.\nCentroids are marked with red ‚ÄúX‚Äù symbols, showing the final positions of the centroids after training."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/decision_tree.html",
    "href": "insights/StatisticsandProbability/MachineLearning/decision_tree.html",
    "title": "Decision Tree implementation from scratch with Python",
    "section": "",
    "text": "A decision tree is a type of machine learning algorithm used for classification and regression tasks. It consists of a tree-like structure where each internal node represents a feature or attribute, each branch represents a decision based on that feature, and each leaf node represents a predicted output.\nTo train a decision tree, the algorithm uses a dataset with labeled examples to create the tree structure. It starts with the root node, which includes all the examples, and selects the feature that provides the most information gain to split the data into two subsets. It then repeats this process for each subset until it reaches a stopping criterion, such as a maximum tree depth or minimum number of examples in a leaf node.\nOnce the decision tree is trained, it can be used to predict the output for new, unseen examples. To make a prediction, the algorithm starts at the root node and follows the branches based on the values of the input features until it reaches a leaf node. The predicted output for that example is the value associated with the leaf node.\nDecision trees have several advantages, such as being easy to interpret and visualize, handling both numerical and categorical data, and handling missing values. However, they can also suffer from overfitting if the tree is too complex or if there is noise or outliers in the data.\nTo address this issue, various techniques such as pruning, ensemble methods, and regularization can be used to simplify the decision tree or combine multiple trees to improve generalization performance. Additionally, decision trees may not perform well with highly imbalanced datasets or datasets with many irrelevant features, and they may not be suitable for tasks where the relationships between features and outputs are highly nonlinear or complex."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/decision_tree.html#code-implementation",
    "href": "insights/StatisticsandProbability/MachineLearning/decision_tree.html#code-implementation",
    "title": "Decision Tree implementation from scratch with Python",
    "section": "Code Implementation",
    "text": "Code Implementation\nThis code is an implementation of a basic Decision Tree Classifier using the Gini impurity for decision tree splitting.\nLet‚Äôs break it down step by step:\n\nThe DecisionTree class implements a decision tree classifier. It has methods for fitting the model to the training data and making predictions on new data. It contains max_depth: This parameter limits how deep the tree can grow. If max_depth is set to None, the tree will grow until it can no longer improve the Gini impurity (i.e., when all data points in a node are from the same class).\nThe method fit trains the decision tree using the training data X and the corresponding labels y. It initializes the number of classes (n_classes_) and the number of features (n_features_). It then calls the _grow_tree method to build the decision tree.\nThe predict method makes predictions on a test dataset X. It does this by traversing the decision tree for each data point.\nThe gini method calculates the Gini impurity of a set of labels ( y ). It is used to measure how ‚Äúimpure‚Äù a node is. If all the labels in a node are the same, the Gini impurity is zero (pure node). The formula for Gini impurity is:\n\n\\[ Gini(y) = 1 - \\sum \\left( \\frac{\\text{count}(y_i)}{n} \\right)^2 \\]\nWhere:\n\n( (y_i) ) is the frequency of class ( y_i ) in the node.\n( n ) is the total number of data points in that node.\n\n\nThe _best_split method finds the best feature and threshold to split the data at each node. It calculates the Gini impurity for each possible split and selects the one that minimizes the Gini impurity.\n\nHere‚Äôs how it works:\nFor each feature:\n\nSort the data by the feature values.\nFor each possible threshold (based on the values of the feature), divide the data into two groups: left and right of the threshold.\nCalculate the Gini impurity of both groups (left and right) and find the best threshold that minimizes the combined Gini impurity.\n\nThe function returns:\n\nbest_idx: the feature index that provides the best split.\nbest_thr: the threshold value that minimizes the Gini impurity\n\n\nThe _grow_tree method builds the decision tree recursively. It splits the data at each node and creates child nodes until one of the following stopping criteria is met:\n\n\nThe depth of the tree reaches max_depth.\nThe node contains data that cannot be split further (all data points belong to the same class).\n\nAt each node:\n\nThe majority class is determined and used as the predicted class for that node.\nThe tree is recursively split using the best feature and threshold.\n\n\nThe _predict method takes a data point and traverses the decision tree until it reaches a leaf node. It then returns the predicted class of that leaf node.\n\n\nimport numpy as np\n\nclass DecisionTree:\n    def __init__(self, max_depth=None):\n        self.max_depth = max_depth\n        \n    def fit(self, X, y):\n        self.n_classes_ = len(np.unique(y))  # Number of unique classes\n        self.n_features_ = X.shape[1]  # Number of features\n        self.tree_ = self._grow_tree(X, y)  # Build the tree\n        \n    def predict(self, X):\n        return [self._predict(inputs) for inputs in X]\n        \n    def _gini(self, y):\n        _, counts = np.unique(y, return_counts=True)\n        impurity = 1 - np.sum([(count / len(y)) ** 2 for count in counts])\n        return impurity\n        \n    def _best_split(self, X, y):\n        m = y.size\n        if m &lt;= 1:\n            return None, None\n        \n        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n        best_idx, best_thr = None, None\n        \n        for idx in range(self.n_features_):\n            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n            num_left = [0] * self.n_classes_\n            num_right = num_parent.copy()\n            for i in range(1, m):\n                c = classes[i - 1]\n                num_left[c] += 1\n                num_right[c] -= 1\n                gini_left = 1.0 - sum(\n                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n                )\n                gini_right = 1.0 - sum(\n                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n                )\n                gini = (i * gini_left + (m - i) * gini_right) / m\n                if thresholds[i] == thresholds[i - 1]:\n                    continue\n                if gini &lt; best_gini:\n                    best_gini = gini\n                    best_idx = idx\n                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n        \n        return best_idx, best_thr\n        \n    def _grow_tree(self, X, y, depth=0):\n        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n        predicted_class = np.argmax(num_samples_per_class)\n        node = Node(predicted_class=predicted_class)\n        if depth &lt; self.max_depth:\n            idx, thr = self._best_split(X, y)\n            if idx is not None:\n                indices_left = X[:, idx] &lt; thr\n                X_left, y_left = X[indices_left], y[indices_left]\n                X_right, y_right = X[~indices_left], y[~indices_left]\n                node.feature_index = idx\n                node.threshold = thr\n                node.left = self._grow_tree(X_left, y_left, depth + 1)\n                node.right = self._grow_tree(X_right, y_right, depth + 1)\n        return node\n        \n    def _predict(self, inputs):\n        node = self.tree_\n        while node.left:\n            if inputs[node.feature_index] &lt; node.threshold:\n                node = node.left\n            else:\n                node = node.right\n        return node.predicted_class\n    \nclass Node:\n    def __init__(self, *, predicted_class):\n        self.predicted_class = predicted_class\n        self.feature_index = 0\n        self.threshold = 0.0 \n        self.left = None\n        self.right = None\n\n    def is_leaf_node(self):\n        return self.left is None and self.right is None\n\nLet‚Äôs run an example with a simple dataset and visualize the decision tree. We‚Äôll use the Iris dataset, which is commonly used for classification tasks, and visualize how the decision tree splits the data based on features.\n\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n\n# Load the Iris dataset\niris = load_iris()\nX = iris.data[:, :2]  # Only using the first two features (sepal length, sepal width)\ny = iris.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize and train the Decision Tree classifier\ntree = DecisionTree(max_depth=3)\ntree.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = tree.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\nAccuracy: 0.78"
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/decision_tree.html#visualization",
    "href": "insights/StatisticsandProbability/MachineLearning/decision_tree.html#visualization",
    "title": "Decision Tree implementation from scratch with Python",
    "section": "Visualization",
    "text": "Visualization\nWe visualize the decision boundaries of the decision tree based on the first two features of the Iris dataset (sepal length and sepal width).\n\n# Visualization of the decision boundaries\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                     np.arange(y_min, y_max, 0.1))\n\nZ = np.array([tree._predict([x, y]) for x, y in zip(xx.ravel(), yy.ravel())])\nZ = Z.reshape(xx.shape)\n\n\nplt.contourf(xx, yy, Z, alpha=0.3)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolor='k')\nplt.title(\"Decision Tree Classifier - Decision Boundaries\")\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\nplt.show()\n\n\n\n\n\n\n\n\nIn the above example,\n\nWe create a mesh grid to cover the entire feature space (sepal length and sepal width).\nFor each point on the grid, we predict its class using the trained decision tree and plot the decision boundaries.\nData points are also plotted on top of the decision boundary with different colors representing different classes."
  },
  {
    "objectID": "insights/StatisticsandProbability/MachineLearning/decision_tree.html#what-is-decision-tree",
    "href": "insights/StatisticsandProbability/MachineLearning/decision_tree.html#what-is-decision-tree",
    "title": "Decision Tree implementation from scratch with Python",
    "section": "What is Decision Tree?",
    "text": "What is Decision Tree?\nA decision tree is a type of machine learning algorithm used for classification and regression tasks. It consists of a tree-like structure where each internal node represents a feature or attribute, each branch represents a decision based on that feature, and each leaf node represents a predicted output.\nTo train a decision tree, the algorithm uses a dataset with labeled examples to create the tree structure. It starts with the root node, which includes all the examples, and selects the feature that provides the most information gain to split the data into two subsets. It then repeats this process for each subset until it reaches a stopping criterion, such as a maximum tree depth or minimum number of examples in a leaf node.\nOnce the decision tree is trained, it can be used to predict the output for new, unseen examples. To make a prediction, the algorithm starts at the root node and follows the branches based on the values of the input features until it reaches a leaf node. The predicted output for that example is the value associated with the leaf node.\nDecision trees have several advantages, such as being easy to interpret and visualize, handling both numerical and categorical data, and handling missing values. However, they can also suffer from overfitting if the tree is too complex or if there is noise or outliers in the data.\nTo address this issue, various techniques such as pruning, ensemble methods, and regularization can be used to simplify the decision tree or combine multiple trees to improve generalization performance. Additionally, decision trees may not perform well with highly imbalanced datasets or datasets with many irrelevant features, and they may not be suitable for tasks where the relationships between features and outputs are highly nonlinear or complex."
  }
]